{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previews データ予測モデル\n",
    "\n",
    "対象：2016年～2025年の過去データから、当日のPreviewsデータを予測\n",
    "\n",
    "## 実装内容\n",
    "1. **展示タイム予測モデル**（GradientBoostingRegressor） ★★★★★\n",
    "2. **進入コース予測モデル**（GradientBoostingClassifier） ★★★★★\n",
    "3. **スタート展示予測モデル**（GradientBoostingRegressor） ★★★★☆\n",
    "4. **チルト調整予測モデル**（GradientBoostingRegressor） ★★★☆☆\n",
    "\n",
    "## 出力\n",
    "予測Previewsデータを `data/prediction-preview/YYYY/MM/DD.csv` に保存\n",
    "\n",
    "## 目標精度\n",
    "- 展示タイム: MAE < 0.05秒\n",
    "- 進入コース: 的中率 > 70%\n",
    "- スタート展示: MAE < 0.10秒\n",
    "- チルト調整: 的中率 > 60%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository root: /Users/mahiguch/dev/boatrace/data\n",
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import calendar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "cwd = Path.cwd()\n",
    "repo_root = cwd if (cwd / 'data').exists() else cwd.parent.parent\n",
    "\n",
    "print(f'Repository root: {repo_root}')\n",
    "print('Setup complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ変形関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshape functions ready\n"
     ]
    }
   ],
   "source": [
    "def reshape_programs(df):\n",
    "    \"\"\"\n",
    "    Programs を艇単位に変形\n",
    "    Programs の枠 (1枠_～) を艇番として扱う\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    race_cols = ['レースコード', 'レース日', 'レース場', 'レース回']\n",
    "    \n",
    "    for frame in range(1, 7):\n",
    "        prefix = f'{frame}枠_'\n",
    "        cols = [c for c in df.columns if c.startswith(prefix)]\n",
    "        if cols:\n",
    "            tmp = df[race_cols + cols].copy()\n",
    "            tmp.columns = race_cols + [c[len(prefix):] for c in cols]\n",
    "            tmp['艇番'] = frame  # 枠番号 = 艇番\n",
    "            frames.append(tmp)\n",
    "    \n",
    "    return pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
    "\n",
    "def reshape_previews(df):\n",
    "    \"\"\"\n",
    "    Previews を艇単位に変形\n",
    "    各艇の情報を1行に集約\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    \n",
    "    race_cols = ['レースコード', 'レース日', 'レース場', 'レース回']\n",
    "    race_attrs = ['風速(m)', '風向', '波の高さ(cm)', '天候', '気温(℃)', '水温(℃)']\n",
    "    \n",
    "    for boat in range(1, 7):\n",
    "        prefix = f'艇{boat}_'\n",
    "        boat_cols = [c for c in df.columns if c.startswith(prefix)]\n",
    "        if boat_cols:\n",
    "            tmp = df[race_cols + race_attrs + boat_cols].copy()\n",
    "            boat_col_names = [c[len(prefix):] for c in boat_cols]\n",
    "            tmp.columns = race_cols + race_attrs + boat_col_names\n",
    "            tmp['艇番'] = boat\n",
    "            frames.append(tmp)\n",
    "    \n",
    "    return pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
    "\n",
    "def reshape_results(df):\n",
    "    \"\"\"\n",
    "    Results を艇単位に変形\n",
    "    着順情報を艇番とマッチング\n",
    "    \"\"\"\n",
    "    result_list = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        race_code = row['レースコード']\n",
    "        \n",
    "        for place in range(1, 7):\n",
    "            boat_col = f'{place}着_艇番'\n",
    "            if boat_col in df.columns and pd.notna(row[boat_col]):\n",
    "                try:\n",
    "                    boat_num = int(row[boat_col])\n",
    "                    if boat_num < 1 or boat_num > 6:\n",
    "                        continue\n",
    "                    result_list.append({\n",
    "                        'レースコード': race_code,\n",
    "                        '艇番': boat_num,\n",
    "                        '着順': place\n",
    "                    })\n",
    "                except (ValueError, TypeError):\n",
    "                    continue\n",
    "    \n",
    "    return pd.DataFrame(result_list) if result_list else pd.DataFrame()\n",
    "\n",
    "print('Reshape functions ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2016～2025年の過去データで特徴量を抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 365 days (2025 only)\n"
     ]
    }
   ],
   "source": [
    "# Load data for 2025 only\n",
    "all_data = {}\n",
    "year = '2025'\n",
    "\n",
    "for month in range(1, 13):\n",
    "    _, max_day = calendar.monthrange(int(year), month)\n",
    "    for day in range(1, max_day + 1):\n",
    "        month_str = f'{month:02d}'\n",
    "        day_str = f'{day:02d}'\n",
    "        prog_path = repo_root / 'data' / 'programs' / year / month_str / f'{day_str}.csv'\n",
    "        prev_path = repo_root / 'data' / 'previews' / year / month_str / f'{day_str}.csv'\n",
    "        res_path = repo_root / 'data' / 'results' / year / month_str / f'{day_str}.csv'\n",
    "        \n",
    "        if prog_path.exists() and prev_path.exists() and res_path.exists():\n",
    "            date_key = f'{year}-{month_str}-{day_str}'\n",
    "            try:\n",
    "                all_data[date_key] = {\n",
    "                    'programs': pd.read_csv(prog_path),\n",
    "                    'previews': pd.read_csv(prev_path),\n",
    "                    'results': pd.read_csv(res_path)\n",
    "                }\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "print(f'✓ Loaded {len(all_data)} days (2025 only)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Stadium name to number mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stadium mapping ready\n"
     ]
    }
   ],
   "source": [
    "STADIUM_NAME_TO_NUMBER = {\n",
    "    'ボートレース桐生': 1,\n",
    "    'ボートレース戸田': 2,\n",
    "    'ボートレース江戸川': 3,\n",
    "    'ボートレース平和島': 4,\n",
    "    'ボートレース多摩川': 5,\n",
    "    'ボートレース浜名湖': 6,\n",
    "    'ボートレース蒲郡': 7,\n",
    "    'ボートレース常滑': 8,\n",
    "    'ボートレース津': 9,\n",
    "    'ボートレース三国': 10,\n",
    "    'ボートレースびわこ': 11,\n",
    "    'ボートレース琵琶湖': 11,\n",
    "    'ボートレース住之江': 12,\n",
    "    'ボートレース尼崎': 13,\n",
    "    'ボートレース鳴門': 14,\n",
    "    'ボートレース丸亀': 15,\n",
    "    'ボートレース児島': 16,\n",
    "    'ボートレース宮島': 17,\n",
    "    'ボートレース徳山': 18,\n",
    "    'ボートレース下関': 19,\n",
    "    'ボートレース若松': 20,\n",
    "    'ボートレース芦屋': 21,\n",
    "    'ボートレース福岡': 22,\n",
    "    'ボートレース唐津': 23,\n",
    "    'ボートレース大村': 24,\n",
    "}\n",
    "\n",
    "def map_stadium_name_to_number(stadium_name):\n",
    "    if pd.isna(stadium_name):\n",
    "        return np.nan\n",
    "    stadium_name = str(stadium_name).strip()\n",
    "    return STADIUM_NAME_TO_NUMBER.get(stadium_name, np.nan)\n",
    "\n",
    "print('Stadium mapping ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. データ統合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 2025-01-01: (792, 46) (features: 39)\n",
      "✓ 2025-01-02: (792, 46) (features: 39)\n",
      "✓ 2025-01-03: (888, 46) (features: 39)\n",
      "✓ 2025-01-04: (912, 46) (features: 39)\n",
      "✓ 2025-01-05: (852, 46) (features: 39)\n",
      "✓ 2025-01-06: (648, 46) (features: 39)\n",
      "✓ 2025-01-07: (720, 46) (features: 39)\n",
      "✓ 2025-01-08: (720, 46) (features: 39)\n",
      "✓ 2025-01-09: (720, 46) (features: 39)\n",
      "✓ 2025-01-10: (618, 46) (features: 39)\n",
      "✓ 2025-01-11: (936, 46) (features: 39)\n",
      "✓ 2025-01-12: (864, 46) (features: 39)\n",
      "✓ 2025-01-13: (1008, 46) (features: 39)\n",
      "✓ 2025-01-14: (936, 46) (features: 39)\n",
      "✓ 2025-01-15: (792, 46) (features: 39)\n",
      "✓ 2025-01-16: (864, 46) (features: 39)\n",
      "✓ 2025-01-17: (1074, 46) (features: 39)\n",
      "✓ 2025-01-18: (1074, 46) (features: 39)\n",
      "✓ 2025-01-19: (1140, 46) (features: 39)\n",
      "✓ 2025-01-20: (930, 46) (features: 39)\n",
      "✓ 2025-01-21: (858, 46) (features: 39)\n",
      "✓ 2025-01-22: (858, 46) (features: 39)\n",
      "✓ 2025-01-23: (930, 46) (features: 39)\n",
      "✓ 2025-01-24: (931, 46) (features: 39)\n",
      "✓ 2025-01-25: (936, 46) (features: 39)\n",
      "✓ 2025-01-26: (1080, 46) (features: 39)\n",
      "✓ 2025-01-27: (864, 46) (features: 39)\n",
      "✓ 2025-01-28: (942, 46) (features: 39)\n",
      "✓ 2025-01-29: (792, 46) (features: 39)\n",
      "✓ 2025-01-30: (936, 46) (features: 39)\n",
      "✓ 2025-01-31: (1152, 46) (features: 39)\n",
      "✓ 2025-02-01: (1074, 46) (features: 39)\n",
      "✓ 2025-02-02: (1074, 46) (features: 39)\n",
      "✓ 2025-02-03: (1074, 46) (features: 39)\n",
      "✓ 2025-02-04: (930, 46) (features: 39)\n",
      "✓ 2025-02-05: (720, 46) (features: 39)\n",
      "✓ 2025-02-06: (786, 46) (features: 39)\n",
      "✓ 2025-02-07: (720, 46) (features: 39)\n",
      "✓ 2025-02-08: (792, 46) (features: 39)\n",
      "✓ 2025-02-09: (1008, 46) (features: 39)\n",
      "✓ 2025-02-10: (1074, 46) (features: 39)\n",
      "✓ 2025-02-11: (858, 46) (features: 39)\n",
      "✓ 2025-02-12: (786, 46) (features: 39)\n",
      "✓ 2025-02-13: (786, 46) (features: 39)\n",
      "✓ 2025-02-14: (918, 46) (features: 39)\n",
      "✓ 2025-02-15: (1080, 46) (features: 39)\n",
      "✓ 2025-02-16: (1008, 46) (features: 39)\n",
      "✓ 2025-02-17: (978, 46) (features: 39)\n",
      "✓ 2025-02-18: (1003, 46) (features: 39)\n",
      "✓ 2025-02-19: (1080, 46) (features: 39)\n",
      "✓ 2025-02-20: (858, 46) (features: 39)\n",
      "✓ 2025-02-21: (930, 46) (features: 39)\n",
      "✓ 2025-02-22: (1068, 46) (features: 39)\n",
      "✓ 2025-02-23: (1134, 46) (features: 39)\n",
      "✓ 2025-02-24: (1056, 46) (features: 39)\n",
      "✓ 2025-02-25: (1080, 46) (features: 39)\n",
      "✓ 2025-02-26: (1008, 46) (features: 39)\n",
      "✓ 2025-02-27: (1008, 46) (features: 39)\n",
      "✓ 2025-02-28: (864, 46) (features: 39)\n",
      "✓ 2025-03-01: (1008, 46) (features: 39)\n",
      "✓ 2025-03-02: (930, 46) (features: 39)\n",
      "✓ 2025-03-03: (948, 46) (features: 39)\n",
      "✓ 2025-03-04: (840, 46) (features: 39)\n",
      "✓ 2025-03-05: (852, 46) (features: 39)\n",
      "✓ 2025-03-06: (912, 46) (features: 39)\n",
      "✓ 2025-03-07: (918, 46) (features: 39)\n",
      "✓ 2025-03-08: (1056, 46) (features: 39)\n",
      "✓ 2025-03-09: (930, 46) (features: 39)\n",
      "✓ 2025-03-10: (864, 46) (features: 39)\n",
      "✓ 2025-03-11: (792, 46) (features: 39)\n",
      "✓ 2025-03-12: (864, 46) (features: 39)\n",
      "✓ 2025-03-13: (1014, 46) (features: 39)\n",
      "✓ 2025-03-14: (1224, 46) (features: 39)\n",
      "✓ 2025-03-15: (1218, 46) (features: 39)\n",
      "✓ 2025-03-16: (1146, 46) (features: 39)\n",
      "✓ 2025-03-17: (930, 46) (features: 39)\n",
      "✓ 2025-03-18: (642, 46) (features: 39)\n",
      "✓ 2025-03-19: (774, 46) (features: 39)\n",
      "✓ 2025-03-20: (1002, 46) (features: 39)\n",
      "✓ 2025-03-21: (930, 46) (features: 39)\n",
      "✓ 2025-03-22: (870, 46) (features: 39)\n",
      "✓ 2025-03-23: (936, 46) (features: 39)\n",
      "✓ 2025-03-24: (936, 46) (features: 39)\n",
      "✓ 2025-03-25: (930, 46) (features: 39)\n",
      "✓ 2025-03-26: (858, 46) (features: 39)\n",
      "✓ 2025-03-27: (990, 46) (features: 39)\n",
      "✓ 2025-03-28: (786, 46) (features: 39)\n",
      "✓ 2025-03-29: (858, 46) (features: 39)\n",
      "✓ 2025-03-30: (858, 46) (features: 39)\n",
      "✓ 2025-03-31: (792, 46) (features: 39)\n",
      "✓ 2025-04-01: (720, 46) (features: 39)\n",
      "✓ 2025-04-02: (792, 46) (features: 39)\n",
      "✓ 2025-04-03: (864, 46) (features: 39)\n",
      "✓ 2025-04-04: (864, 46) (features: 39)\n",
      "✓ 2025-04-05: (912, 46) (features: 39)\n",
      "✓ 2025-04-06: (840, 46) (features: 39)\n",
      "✓ 2025-04-07: (780, 46) (features: 39)\n",
      "✓ 2025-04-08: (852, 46) (features: 39)\n",
      "✓ 2025-04-09: (864, 46) (features: 39)\n",
      "✓ 2025-04-10: (780, 46) (features: 39)\n",
      "✓ 2025-04-11: (780, 46) (features: 39)\n",
      "✓ 2025-04-12: (648, 46) (features: 39)\n",
      "✓ 2025-04-13: (504, 46) (features: 39)\n",
      "✓ 2025-04-14: (432, 46) (features: 39)\n",
      "✓ 2025-04-15: (576, 46) (features: 39)\n",
      "✓ 2025-04-16: (432, 46) (features: 39)\n",
      "✓ 2025-04-17: (432, 46) (features: 39)\n",
      "✓ 2025-04-18: (636, 46) (features: 39)\n",
      "✓ 2025-04-19: (576, 46) (features: 39)\n",
      "✓ 2025-04-20: (576, 46) (features: 39)\n",
      "✓ 2025-04-21: (504, 46) (features: 39)\n",
      "✓ 2025-04-22: (576, 46) (features: 39)\n",
      "✓ 2025-04-23: (528, 46) (features: 39)\n",
      "✓ 2025-04-24: (786, 46) (features: 39)\n",
      "✓ 2025-04-25: (708, 46) (features: 39)\n",
      "✓ 2025-04-26: (846, 46) (features: 39)\n",
      "✓ 2025-04-27: (912, 46) (features: 39)\n",
      "✓ 2025-04-28: (720, 46) (features: 39)\n",
      "✓ 2025-04-29: (792, 46) (features: 39)\n",
      "✓ 2025-04-30: (648, 46) (features: 39)\n",
      "✓ 2025-05-01: (576, 46) (features: 39)\n",
      "✓ 2025-05-02: (576, 46) (features: 39)\n",
      "✓ 2025-05-03: (804, 46) (features: 39)\n",
      "✓ 2025-05-04: (1008, 46) (features: 39)\n",
      "✓ 2025-05-05: (1058, 46) (features: 39)\n",
      "✓ 2025-05-06: (1068, 46) (features: 39)\n",
      "✓ 2025-05-07: (792, 46) (features: 39)\n",
      "✓ 2025-05-08: (648, 46) (features: 39)\n",
      "✓ 2025-05-09: (648, 46) (features: 39)\n",
      "✓ 2025-05-10: (648, 46) (features: 39)\n",
      "✓ 2025-05-11: (576, 46) (features: 39)\n",
      "✓ 2025-05-12: (792, 46) (features: 39)\n",
      "✓ 2025-05-13: (648, 46) (features: 39)\n",
      "✓ 2025-05-14: (648, 46) (features: 39)\n",
      "✓ 2025-05-15: (648, 46) (features: 39)\n",
      "✓ 2025-05-16: (498, 46) (features: 39)\n",
      "✓ 2025-05-17: (648, 46) (features: 39)\n",
      "✓ 2025-05-18: (787, 46) (features: 39)\n",
      "✓ 2025-05-19: (864, 46) (features: 39)\n",
      "✓ 2025-05-20: (792, 46) (features: 39)\n",
      "✓ 2025-05-21: (865, 46) (features: 39)\n",
      "✓ 2025-05-22: (792, 46) (features: 39)\n",
      "✓ 2025-05-23: (786, 46) (features: 39)\n",
      "✓ 2025-05-24: (648, 46) (features: 39)\n",
      "✓ 2025-05-25: (648, 46) (features: 39)\n",
      "✓ 2025-05-26: (504, 46) (features: 39)\n",
      "✓ 2025-05-27: (288, 46) (features: 39)\n",
      "✓ 2025-05-28: (432, 46) (features: 39)\n",
      "✓ 2025-05-29: (432, 46) (features: 39)\n",
      "✓ 2025-05-30: (288, 46) (features: 39)\n",
      "✓ 2025-05-31: (576, 46) (features: 39)\n",
      "✓ 2025-06-01: (936, 46) (features: 39)\n",
      "✓ 2025-06-02: (720, 46) (features: 39)\n",
      "✓ 2025-06-03: (720, 46) (features: 39)\n",
      "✓ 2025-06-04: (576, 46) (features: 39)\n",
      "✓ 2025-06-05: (576, 46) (features: 39)\n",
      "✓ 2025-06-06: (504, 46) (features: 39)\n",
      "✓ 2025-06-07: (576, 46) (features: 39)\n",
      "✓ 2025-06-08: (588, 46) (features: 39)\n",
      "✓ 2025-06-09: (696, 46) (features: 39)\n",
      "✓ 2025-06-10: (756, 46) (features: 39)\n",
      "✓ 2025-06-11: (756, 46) (features: 39)\n",
      "✓ 2025-06-12: (624, 46) (features: 39)\n",
      "✓ 2025-06-13: (648, 46) (features: 39)\n",
      "✓ 2025-06-14: (792, 46) (features: 39)\n",
      "✓ 2025-06-15: (864, 46) (features: 39)\n",
      "✓ 2025-06-16: (576, 46) (features: 39)\n",
      "✓ 2025-06-17: (432, 46) (features: 39)\n",
      "✓ 2025-06-18: (648, 46) (features: 39)\n",
      "✓ 2025-06-19: (732, 46) (features: 39)\n",
      "✓ 2025-06-20: (840, 46) (features: 39)\n",
      "✓ 2025-06-21: (636, 46) (features: 39)\n",
      "✓ 2025-06-22: (624, 46) (features: 39)\n",
      "✓ 2025-06-23: (714, 46) (features: 39)\n",
      "✓ 2025-06-24: (648, 46) (features: 39)\n",
      "✓ 2025-06-25: (648, 46) (features: 39)\n",
      "✓ 2025-06-26: (576, 46) (features: 39)\n",
      "✓ 2025-06-27: (576, 46) (features: 39)\n",
      "✓ 2025-06-28: (720, 46) (features: 39)\n",
      "✓ 2025-06-29: (721, 46) (features: 39)\n",
      "✓ 2025-06-30: (432, 46) (features: 39)\n",
      "✓ 2025-07-01: (648, 46) (features: 39)\n",
      "✓ 2025-07-02: (780, 46) (features: 39)\n",
      "✓ 2025-07-03: (708, 46) (features: 39)\n",
      "✓ 2025-07-04: (684, 46) (features: 39)\n",
      "✓ 2025-07-05: (774, 46) (features: 39)\n",
      "✓ 2025-07-06: (756, 46) (features: 39)\n",
      "✓ 2025-07-07: (625, 46) (features: 39)\n",
      "✓ 2025-07-08: (504, 46) (features: 39)\n",
      "✓ 2025-07-09: (576, 46) (features: 39)\n",
      "✓ 2025-07-10: (648, 46) (features: 39)\n",
      "✓ 2025-07-11: (576, 46) (features: 39)\n",
      "✓ 2025-07-12: (720, 46) (features: 39)\n",
      "✓ 2025-07-13: (858, 46) (features: 39)\n",
      "✓ 2025-07-14: (564, 46) (features: 39)\n",
      "✓ 2025-07-15: (624, 46) (features: 39)\n",
      "✓ 2025-07-16: (552, 46) (features: 39)\n",
      "✓ 2025-07-17: (684, 46) (features: 39)\n",
      "✓ 2025-07-18: (786, 46) (features: 39)\n",
      "✓ 2025-07-19: (864, 46) (features: 39)\n",
      "✓ 2025-07-20: (936, 46) (features: 39)\n",
      "✓ 2025-07-21: (792, 46) (features: 39)\n",
      "✓ 2025-07-22: (720, 46) (features: 39)\n",
      "✓ 2025-07-23: (570, 46) (features: 39)\n",
      "✓ 2025-07-24: (552, 46) (features: 39)\n",
      "✓ 2025-07-25: (636, 46) (features: 39)\n",
      "✓ 2025-07-26: (624, 46) (features: 39)\n",
      "✓ 2025-07-27: (708, 46) (features: 39)\n",
      "✓ 2025-07-28: (696, 46) (features: 39)\n",
      "✓ 2025-07-29: (720, 46) (features: 39)\n",
      "✓ 2025-07-30: (504, 46) (features: 39)\n",
      "✓ 2025-07-31: (648, 46) (features: 39)\n",
      "✓ 2025-08-01: (696, 46) (features: 39)\n",
      "✓ 2025-08-02: (678, 46) (features: 39)\n",
      "✓ 2025-08-03: (816, 46) (features: 39)\n",
      "✓ 2025-08-04: (816, 46) (features: 39)\n",
      "✓ 2025-08-05: (816, 46) (features: 39)\n",
      "✓ 2025-08-06: (768, 46) (features: 39)\n",
      "✓ 2025-08-07: (576, 46) (features: 39)\n",
      "✓ 2025-08-08: (720, 46) (features: 39)\n",
      "✓ 2025-08-09: (576, 46) (features: 39)\n",
      "✓ 2025-08-10: (792, 46) (features: 39)\n",
      "✓ 2025-08-11: (888, 46) (features: 39)\n",
      "✓ 2025-08-12: (852, 46) (features: 39)\n",
      "✓ 2025-08-13: (912, 46) (features: 39)\n",
      "✓ 2025-08-14: (852, 46) (features: 39)\n",
      "✓ 2025-08-15: (900, 46) (features: 39)\n",
      "✓ 2025-08-16: (840, 46) (features: 39)\n",
      "✓ 2025-08-17: (864, 46) (features: 39)\n",
      "✓ 2025-08-18: (792, 46) (features: 39)\n",
      "✓ 2025-08-19: (648, 46) (features: 39)\n",
      "✓ 2025-08-20: (648, 46) (features: 39)\n",
      "✓ 2025-08-21: (564, 46) (features: 39)\n",
      "✓ 2025-08-22: (577, 46) (features: 39)\n",
      "✓ 2025-08-23: (432, 46) (features: 39)\n",
      "✓ 2025-08-24: (570, 46) (features: 39)\n",
      "✓ 2025-08-25: (564, 46) (features: 39)\n",
      "✓ 2025-08-26: (768, 46) (features: 39)\n",
      "✓ 2025-08-27: (576, 46) (features: 39)\n",
      "✓ 2025-08-28: (576, 46) (features: 39)\n",
      "✓ 2025-08-29: (576, 46) (features: 39)\n",
      "✓ 2025-08-30: (936, 46) (features: 39)\n",
      "✓ 2025-08-31: (720, 46) (features: 39)\n",
      "✓ 2025-09-01: (408, 46) (features: 39)\n",
      "✓ 2025-09-02: (416, 46) (features: 39)\n",
      "✓ 2025-09-03: (534, 46) (features: 39)\n",
      "✓ 2025-09-04: (624, 46) (features: 39)\n",
      "✓ 2025-09-05: (360, 46) (features: 39)\n",
      "✓ 2025-09-06: (492, 46) (features: 39)\n",
      "✓ 2025-09-07: (432, 46) (features: 39)\n",
      "✓ 2025-09-08: (360, 46) (features: 39)\n",
      "✓ 2025-09-09: (420, 46) (features: 39)\n",
      "✓ 2025-09-10: (564, 46) (features: 39)\n",
      "✓ 2025-09-11: (516, 46) (features: 39)\n",
      "✓ 2025-09-12: (576, 46) (features: 39)\n",
      "✓ 2025-09-13: (648, 46) (features: 39)\n",
      "✓ 2025-09-14: (648, 46) (features: 39)\n",
      "✓ 2025-09-15: (648, 46) (features: 39)\n",
      "✓ 2025-09-16: (576, 46) (features: 39)\n",
      "✓ 2025-09-17: (504, 46) (features: 39)\n",
      "✓ 2025-09-18: (576, 46) (features: 39)\n",
      "✓ 2025-09-19: (504, 46) (features: 39)\n",
      "✓ 2025-09-20: (576, 46) (features: 39)\n",
      "✓ 2025-09-21: (672, 46) (features: 39)\n",
      "✓ 2025-09-22: (864, 46) (features: 39)\n",
      "✓ 2025-09-23: (576, 46) (features: 39)\n",
      "✓ 2025-09-24: (576, 46) (features: 39)\n",
      "✓ 2025-09-25: (588, 46) (features: 39)\n",
      "✓ 2025-09-26: (546, 46) (features: 39)\n",
      "✓ 2025-09-27: (432, 46) (features: 39)\n",
      "✓ 2025-09-28: (504, 46) (features: 39)\n",
      "✓ 2025-09-29: (792, 46) (features: 39)\n",
      "✓ 2025-09-30: (576, 46) (features: 39)\n",
      "✓ 2025-10-01: (432, 46) (features: 39)\n",
      "✓ 2025-10-02: (504, 46) (features: 39)\n",
      "✓ 2025-10-03: (360, 46) (features: 39)\n",
      "✓ 2025-10-04: (576, 46) (features: 39)\n",
      "✓ 2025-10-05: (576, 46) (features: 39)\n",
      "✓ 2025-10-06: (504, 46) (features: 39)\n",
      "✓ 2025-10-07: (577, 46) (features: 39)\n",
      "✓ 2025-10-08: (498, 46) (features: 39)\n",
      "✓ 2025-10-09: (348, 46) (features: 39)\n",
      "✓ 2025-10-10: (396, 46) (features: 39)\n",
      "✓ 2025-10-11: (678, 46) (features: 39)\n",
      "✓ 2025-10-12: (612, 46) (features: 39)\n",
      "✓ 2025-10-13: (540, 46) (features: 39)\n",
      "✓ 2025-10-14: (570, 46) (features: 39)\n",
      "✓ 2025-10-15: (636, 46) (features: 39)\n",
      "✓ 2025-10-16: (576, 46) (features: 39)\n",
      "✓ 2025-10-17: (576, 46) (features: 39)\n",
      "✓ 2025-10-18: (576, 46) (features: 39)\n",
      "✓ 2025-10-19: (648, 46) (features: 39)\n",
      "✓ 2025-10-20: (504, 46) (features: 39)\n",
      "✓ 2025-10-21: (516, 46) (features: 39)\n",
      "✓ 2025-10-22: (528, 46) (features: 39)\n",
      "✓ 2025-10-23: (540, 46) (features: 39)\n",
      "✓ 2025-10-24: (654, 46) (features: 39)\n",
      "✓ 2025-10-25: (492, 46) (features: 39)\n",
      "✓ 2025-10-26: (564, 46) (features: 39)\n",
      "✓ 2025-10-27: (504, 46) (features: 39)\n",
      "✓ 2025-10-28: (426, 46) (features: 39)\n",
      "✓ 2025-10-29: (360, 46) (features: 39)\n",
      "✓ 2025-10-30: (624, 46) (features: 39)\n",
      "✓ 2025-10-31: (672, 46) (features: 39)\n",
      "✓ 2025-11-01: (630, 46) (features: 39)\n",
      "✓ 2025-11-02: (696, 46) (features: 39)\n",
      "✓ 2025-11-03: (576, 46) (features: 39)\n",
      "✓ 2025-11-04: (432, 46) (features: 39)\n",
      "✓ 2025-11-05: (504, 46) (features: 39)\n",
      "✓ 2025-11-06: (433, 46) (features: 39)\n",
      "✓ 2025-11-07: (504, 46) (features: 39)\n",
      "✓ 2025-11-08: (504, 46) (features: 39)\n",
      "✓ 2025-11-09: (582, 46) (features: 39)\n",
      "✓ 2025-11-10: (504, 46) (features: 39)\n",
      "✓ 2025-11-11: (504, 46) (features: 39)\n",
      "✓ 2025-11-12: (360, 46) (features: 39)\n",
      "✓ 2025-11-13: (288, 46) (features: 39)\n",
      "✓ 2025-11-14: (504, 46) (features: 39)\n",
      "✓ 2025-11-15: (312, 46) (features: 39)\n",
      "✓ 2025-11-16: (648, 46) (features: 39)\n",
      "✓ 2025-11-17: (432, 46) (features: 39)\n",
      "✓ 2025-11-18: (438, 46) (features: 39)\n",
      "✓ 2025-11-19: (642, 46) (features: 39)\n",
      "✓ 2025-11-20: (499, 46) (features: 39)\n",
      "✓ 2025-11-21: (504, 46) (features: 39)\n",
      "✓ 2025-11-22: (504, 46) (features: 39)\n",
      "✓ 2025-11-23: (504, 46) (features: 39)\n",
      "✓ 2025-11-24: (360, 46) (features: 39)\n",
      "✓ 2025-11-25: (444, 46) (features: 39)\n",
      "✓ 2025-11-26: (564, 46) (features: 39)\n",
      "✓ 2025-11-27: (492, 46) (features: 39)\n",
      "✓ 2025-11-28: (421, 46) (features: 39)\n",
      "✓ 2025-11-29: (558, 46) (features: 39)\n",
      "✓ 2025-11-30: (607, 46) (features: 39)\n",
      "✓ 2025-12-01: (432, 46) (features: 39)\n",
      "✓ 2025-12-02: (360, 46) (features: 39)\n",
      "✓ 2025-12-03: (360, 46) (features: 39)\n",
      "✓ 2025-12-04: (576, 46) (features: 39)\n",
      "✓ 2025-12-05: (648, 46) (features: 39)\n",
      "✓ 2025-12-06: (576, 46) (features: 39)\n",
      "✓ 2025-12-07: (504, 46) (features: 39)\n",
      "✓ 2025-12-08: (504, 46) (features: 39)\n",
      "✓ 2025-12-09: (660, 46) (features: 39)\n",
      "✓ 2025-12-10: (642, 46) (features: 39)\n",
      "✓ 2025-12-11: (504, 46) (features: 39)\n",
      "✓ 2025-12-12: (504, 46) (features: 39)\n",
      "✓ 2025-12-13: (648, 46) (features: 39)\n",
      "✓ 2025-12-14: (720, 46) (features: 39)\n",
      "✓ 2025-12-15: (672, 46) (features: 39)\n",
      "✓ 2025-12-16: (564, 46) (features: 39)\n",
      "✓ 2025-12-17: (624, 46) (features: 39)\n",
      "✓ 2025-12-18: (516, 46) (features: 39)\n",
      "✓ 2025-12-19: (492, 46) (features: 39)\n",
      "✓ 2025-12-20: (552, 46) (features: 39)\n",
      "✓ 2025-12-21: (504, 46) (features: 39)\n",
      "✓ 2025-12-22: (720, 46) (features: 39)\n",
      "✓ 2025-12-23: (720, 46) (features: 39)\n",
      "✓ 2025-12-24: (1008, 46) (features: 39)\n",
      "✓ 2025-12-25: (648, 46) (features: 39)\n",
      "✓ 2025-12-26: (648, 46) (features: 39)\n",
      "✓ 2025-12-27: (696, 46) (features: 39)\n",
      "✓ 2025-12-28: (708, 46) (features: 39)\n",
      "✓ 2025-12-29: (774, 46) (features: 39)\n",
      "✓ 2025-12-30: (906, 46) (features: 39)\n",
      "✓ 2025-12-31: (792, 46) (features: 39)\n",
      "\n",
      "Before filtering: (255196, 46)\n",
      "Removed rows with 展示タイム = 0: 0\n",
      "After filtering: (255196, 46)\n",
      "Dates: 365\n",
      "Stadiums: 24\n"
     ]
    }
   ],
   "source": [
    "# Combine programs, previews, and results\n",
    "# Using exact logic from stadium.ipynb\n",
    "combined_data = []\n",
    "\n",
    "for date_str, data in all_data.items():\n",
    "    try:\n",
    "        prog = reshape_programs(data['programs'])\n",
    "        prev = reshape_previews(data['previews'])\n",
    "        res = reshape_results(data['results'])\n",
    "        \n",
    "        if prev.empty or prog.empty or res.empty:\n",
    "            continue\n",
    "        \n",
    "        # Step 1: Merge previews + programs\n",
    "        # Handle overlapping columns\n",
    "        prog_cols = set(prog.columns)\n",
    "        prev_cols = set(prev.columns)\n",
    "        overlap_cols = prog_cols & prev_cols - {'レースコード', '艇番'}\n",
    "        \n",
    "        # Remove overlapping columns from programs (keep previews version)\n",
    "        prog_to_merge = prog.drop(columns=list(overlap_cols))\n",
    "        \n",
    "        merged = prev.merge(\n",
    "            prog_to_merge,\n",
    "            on=['レースコード', '艇番'],\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        if merged.empty:\n",
    "            continue\n",
    "        \n",
    "        # Step 2: Merge with results\n",
    "        merged = merged.merge(\n",
    "            res[['レースコード', '艇番', '着順']],\n",
    "            on=['レースコード', '艇番'],\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        merged['日付'] = date_str\n",
    "        combined_data.append(merged)\n",
    "        \n",
    "        # Count features (columns not in metadata)\n",
    "        metadata_cols = {'レースコード', 'レース日', 'レース場', 'レース回', '艇番', '日付', '着順'}\n",
    "        feature_count = len([c for c in merged.columns if c not in metadata_cols])\n",
    "        print(f'✓ {date_str}: {merged.shape} (features: {feature_count})')\n",
    "    except Exception as e:\n",
    "        print(f'✗ {date_str}: {type(e).__name__}: {str(e)[:80]}')\n",
    "\n",
    "if combined_data:\n",
    "    final_data = pd.concat(combined_data, ignore_index=True)\n",
    "    print(f'\\nBefore filtering: {final_data.shape}')\n",
    "    \n",
    "    # Remove abnormal exhibition times (0 is invalid)\n",
    "    initial_count = len(final_data)\n",
    "    final_data = final_data[final_data['展示タイム'] != 0].reset_index(drop=True)\n",
    "    removed_count = initial_count - len(final_data)\n",
    "    \n",
    "    print(f'Removed rows with 展示タイム = 0: {removed_count}')\n",
    "    print(f'After filtering: {final_data.shape}')\n",
    "    print(f'Dates: {final_data[\"日付\"].nunique()}')\n",
    "    print(f'Stadiums: {final_data[\"レース場\"].nunique()}')\n",
    "else:\n",
    "    print('No data merged')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 展示タイム予測モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 特徴量準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== データ準備 ===\n",
      "\n",
      "Final data shape: (255196, 46)\n",
      "Total columns: 46\n",
      "\n",
      "Target columns (to predict):\n",
      "  ✓ 展示タイム: float64, 251444/255196 (98.5%)\n",
      "  ✓ コース: float64, 251466/255196 (98.5%)\n",
      "  ✓ スタート展示: float64, 251437/255196 (98.5%)\n",
      "  ✓ チルト調整: float64, 251717/255196 (98.6%)\n",
      "\n",
      "Features for prediction (29):\n",
      "   1. ボート2連対率\n",
      "   2. ボート番号\n",
      "   3. モーター2連対率\n",
      "   4. モーター番号\n",
      "   5. 今節成績_1-1\n",
      "   6. 今節成績_1-2\n",
      "   7. 今節成績_2-1\n",
      "   8. 今節成績_2-2\n",
      "   9. 今節成績_3-1\n",
      "  10. 今節成績_3-2\n",
      "  11. 今節成績_4-1\n",
      "  12. 今節成績_4-2\n",
      "  13. 今節成績_5-1\n",
      "  14. 今節成績_5-2\n",
      "  15. 今節成績_6-1\n",
      "  ... and 14 more\n"
     ]
    }
   ],
   "source": [
    "# Check columns and prepare features\n",
    "print('=== データ準備 ===\\n')\n",
    "print(f'Final data shape: {final_data.shape}')\n",
    "print(f'Total columns: {len(final_data.columns)}')\n",
    "\n",
    "# Check for target variables (Previews data)\n",
    "target_cols = ['展示タイム', 'コース', 'スタート展示', 'チルト調整']\n",
    "print(f'\\nTarget columns (to predict):')\n",
    "for col in target_cols:\n",
    "    if col in final_data.columns:\n",
    "        non_null = final_data[col].notna().sum()\n",
    "        total = len(final_data)\n",
    "        print(f'  ✓ {col}: {final_data[col].dtype}, {non_null}/{total} ({non_null/total*100:.1f}%)')\n",
    "    else:\n",
    "        print(f'  ✗ {col}: NOT FOUND')\n",
    "\n",
    "# Select features from Programs + Environment\n",
    "exclude_cols = {\n",
    "    'レースコード', 'レース日', 'レース場', 'レース回', 'タイトル',\n",
    "    '艇番', '登録番号', '選手名', '支部',\n",
    "    '着順',  # Result data\n",
    "    '風向', '天候',  # Categorical - need encoding\n",
    "    '展示タイム', 'コース', 'スタート展示', 'チルト調整',  # Target variables\n",
    "    '体重(kg)', '体重調整(kg)',  # Preview-only data (target metadata)\n",
    "}\n",
    "\n",
    "feature_cols = [col for col in final_data.columns if col not in exclude_cols]\n",
    "print(f'\\nFeatures for prediction ({len(feature_cols)}):')\n",
    "for i, col in enumerate(sorted(feature_cols)[:15], 1):  # Show first 15\n",
    "    print(f'  {i:2d}. {col}')\n",
    "if len(feature_cols) > 15:\n",
    "    print(f'  ... and {len(feature_cols) - 15} more')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 展示タイム予測モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 展示タイム予測モデル準備 ===\n",
      "\n",
      "Features: 29\n",
      "Samples: 251444\n",
      "Target (展示タイム) stats:\n",
      "  Mean: 6.816s\n",
      "  Std: 0.118s\n",
      "  Min: 6.340s\n",
      "  Max: 8.670s\n"
     ]
    }
   ],
   "source": [
    "# Prepare features for exhibition time prediction\n",
    "print('=== 展示タイム予測モデル準備 ===\\n')\n",
    "\n",
    "if '展示タイム' not in final_data.columns:\n",
    "    print('ERROR: 展示タイム not found!')\n",
    "    raise KeyError('展示タイム column missing')\n",
    "\n",
    "# Prepare X and y\n",
    "X = final_data[feature_cols].copy()\n",
    "y = final_data['展示タイム'].copy()\n",
    "\n",
    "# Convert to numeric and fill NaN\n",
    "for col in X.columns:\n",
    "    X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "y = pd.to_numeric(y, errors='coerce')\n",
    "\n",
    "# Fill NaN with column medians\n",
    "for col in X.columns:\n",
    "    median_val = X[col].median()\n",
    "    X[col].fillna(median_val if pd.notna(median_val) else 0, inplace=True)\n",
    "\n",
    "# Remove rows with missing target\n",
    "valid = y.notna()\n",
    "X = X[valid].reset_index(drop=True)\n",
    "y = y[valid].reset_index(drop=True)\n",
    "\n",
    "print(f'Features: {len(X.columns)}')\n",
    "print(f'Samples: {len(X)}')\n",
    "print(f'Target (展示タイム) stats:')\n",
    "print(f'  Mean: {y.mean():.3f}s')\n",
    "print(f'  Std: {y.std():.3f}s')\n",
    "print(f'  Min: {y.min():.3f}s')\n",
    "print(f'  Max: {y.max():.3f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 展示タイム予測モデル - レース場別訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 展示タイム予測モデル訓練 ===\n",
      "\n",
      "⚠ Stadium  1: MAE=0.0750s, RMSE=0.0973s (13048 samples)\n",
      "⚠ Stadium  2: MAE=0.0759s, RMSE=0.0978s (14556 samples)\n",
      "⚠ Stadium  3: MAE=0.0728s, RMSE=0.0936s (14112 samples)\n",
      "⚠ Stadium  4: MAE=0.0765s, RMSE=0.0984s (11736 samples)\n",
      "⚠ Stadium  5: MAE=0.0751s, RMSE=0.0987s (13824 samples)\n",
      "⚠ Stadium  6: MAE=0.0738s, RMSE=0.0945s (14268 samples)\n",
      "⚠ Stadium  7: MAE=0.0747s, RMSE=0.0951s (14052 samples)\n",
      "⚠ Stadium  8: MAE=0.0753s, RMSE=0.1001s (15108 samples)\n",
      "⚠ Stadium  9: MAE=0.0753s, RMSE=0.0957s (15134 samples)\n",
      "⚠ Stadium 10: MAE=0.0763s, RMSE=0.0985s (13968 samples)\n",
      "⚠ Stadium 11: MAE=0.0761s, RMSE=0.0975s (13254 samples)\n",
      "⚠ Stadium 12: MAE=0.0685s, RMSE=0.0895s (3744 samples)\n",
      "⚠ Stadium 13: MAE=0.0736s, RMSE=0.0937s (3672 samples)\n",
      "⚠ Stadium 14: MAE=0.0740s, RMSE=0.0966s (7056 samples)\n",
      "⚠ Stadium 15: MAE=0.0771s, RMSE=0.0981s (10614 samples)\n",
      "⚠ Stadium 16: MAE=0.0749s, RMSE=0.0961s (7776 samples)\n",
      "⚠ Stadium 17: MAE=0.0751s, RMSE=0.0990s (7392 samples)\n",
      "⚠ Stadium 18: MAE=0.0737s, RMSE=0.0932s (8472 samples)\n",
      "⚠ Stadium 19: MAE=0.0736s, RMSE=0.0975s (7602 samples)\n",
      "⚠ Stadium 20: MAE=0.0758s, RMSE=0.0986s (8940 samples)\n",
      "⚠ Stadium 21: MAE=0.0746s, RMSE=0.0958s (9144 samples)\n",
      "⚠ Stadium 22: MAE=0.0711s, RMSE=0.0925s (6282 samples)\n",
      "⚠ Stadium 23: MAE=0.0726s, RMSE=0.0931s (3206 samples)\n",
      "⚠ Stadium 24: MAE=0.0758s, RMSE=0.0975s (14484 samples)\n",
      "\n",
      "=== Summary ===\n",
      "Models trained: 24/24\n",
      "Average MAE: 0.0745s\n",
      "Average RMSE: 0.0962s\n"
     ]
    }
   ],
   "source": [
    "# Train exhibition time models per stadium\n",
    "print('\\n=== 展示タイム予測モデル訓練 ===\\n')\n",
    "\n",
    "stadiums = sorted(final_data['レース場'].dropna().unique())\n",
    "exhibition_models = {}\n",
    "results_summary = []\n",
    "\n",
    "for stadium in stadiums:\n",
    "    stadium_mask = final_data['レース場'] == stadium\n",
    "    X_std = X[stadium_mask].reset_index(drop=True)\n",
    "    y_std = y[stadium_mask].reset_index(drop=True)\n",
    "    \n",
    "    if len(X_std) < 100:\n",
    "        print(f'Stadium {int(stadium):2d}: insufficient data ({len(X_std)} samples) - SKIP')\n",
    "        continue\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_std, y_std, test_size=0.2, random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_test_s = scaler.transform(X_test)\n",
    "    \n",
    "    # Train GBRegressor\n",
    "    gbr = GradientBoostingRegressor(n_estimators=150, learning_rate=0.05, max_depth=6, subsample=0.8, random_state=42)\n",
    "    gbr.fit(X_train_s, y_train)\n",
    "    \n",
    "    y_pred = gbr.predict(X_test_s)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    exhibition_models[stadium] = {'model': gbr, 'scaler': scaler, 'features': list(X.columns)}\n",
    "    results_summary.append({'stadium': int(stadium), 'samples': len(X_std), 'mae': mae, 'rmse': rmse})\n",
    "    \n",
    "    status = '✓' if mae < 0.05 else '⚠' if mae < 0.10 else '✗'\n",
    "    print(f'{status} Stadium {int(stadium):2d}: MAE={mae:.4f}s, RMSE={rmse:.4f}s ({len(X_std)} samples)')\n",
    "\n",
    "if results_summary:\n",
    "    results_df = pd.DataFrame(results_summary)\n",
    "    print(f'\\n=== Summary ===')\n",
    "    print(f'Models trained: {len(results_df)}/{len(stadiums)}')\n",
    "    print(f'Average MAE: {results_df[\"mae\"].mean():.4f}s')\n",
    "    print(f'Average RMSE: {results_df[\"rmse\"].mean():.4f}s')\n",
    "else:\n",
    "    print('ERROR: No models trained!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 進入コース予測モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Prepare enhanced features for course entry prediction\nprint('\\n=== 進入コース予測モデル準備（強化特徴量版）===\\n')\n\nif 'コース' not in final_data.columns:\n    print('ERROR: コース not found!')\n    raise KeyError('コース column missing')\n\n# Start with base features (same as exhibition time)\nX_course = final_data[feature_cols].copy()\ny_course = final_data['コース'].copy()\n\n# Add frame number as a feature (枠番 = boat number)\nX_course['枠番'] = final_data['艇番']\n\n# Add player's past course entry tendency\n# Calculate the most common course for each player\nplayer_course_tendency = final_data.groupby('登録番号')['コース'].agg(lambda x: x.mode()[0] if len(x.mode()) > 0 else x.median()).reset_index()\nplayer_course_tendency.columns = ['登録番号', 'プレイヤー進入傾向コース']\nX_course_temp = final_data[['登録番号']].copy()\nX_course_temp = X_course_temp.merge(player_course_tendency, on='登録番号', how='left')\nX_course['プレイヤー進入傾向'] = X_course_temp['プレイヤー進入傾向コース']\n\n# Add stadium-level average course pattern\n# For each stadium, calculate average course per frame position\nstadium_frame_course = final_data.groupby(['レース場', '艇番'])['コース'].mean().reset_index()\nstadium_frame_course.columns = ['レース場', '艇番', 'スタジアム枠別平均コース']\nX_course_temp = final_data[['レース場', '艇番']].copy()\nX_course_temp = X_course_temp.merge(stadium_frame_course, on=['レース場', '艇番'], how='left')\nX_course['スタジアム枠別平均'] = X_course_temp['スタジアム枠別平均コース']\n\n# Add player win rate features (interaction with frame)\nX_course['全国勝率×枠'] = final_data['全国勝率'].fillna(0) * final_data['艇番']\nX_course['当地勝率×枠'] = final_data['当地勝率'].fillna(0) * final_data['艇番']\n\n# Convert to numeric\nfor col in X_course.columns:\n    X_course[col] = pd.to_numeric(X_course[col], errors='coerce')\n\ny_course = pd.to_numeric(y_course, errors='coerce')\n\n# Fill NaN\nfor col in X_course.columns:\n    median_val = X_course[col].median()\n    X_course[col].fillna(median_val if pd.notna(median_val) else 0, inplace=True)\n\n# Remove rows with missing target\nvalid_course = y_course.notna()\nX_course = X_course[valid_course].reset_index(drop=True)\ny_course = y_course[valid_course].reset_index(drop=True)\ny_course = y_course.astype(int)\n\nprint(f'Base features: {len(feature_cols)}')\nprint(f'Added features: 5 (枠番, プレイヤー進入傾向, スタジアム枠別平均, 全国勝率×枠, 当地勝率×枠)')\nprint(f'Total features: {len(X_course.columns)}')\nprint(f'Samples: {len(X_course)}')\nprint(f'Target (コース) distribution:')\nfor course in sorted(y_course.unique()):\n    count = (y_course == course).sum()\n    pct = count / len(y_course) * 100\n    print(f'  Course {int(course)}: {count} ({pct:.1f}%)')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 進入コース予測モデル - レース場別訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train course entry models per stadium - improved hyperparameters\nprint('\\n=== 進入コース予測モデル訓練（改善版）===\\n')\n\ncourse_models = {}\nresults_summary_course = []\n\nfor stadium in stadiums:\n    stadium_mask = final_data['レース場'] == stadium\n    X_std = X_course[stadium_mask].reset_index(drop=True)\n    y_std = y_course[stadium_mask].reset_index(drop=True)\n    \n    if len(X_std) < 100:\n        print(f'Stadium {int(stadium):2d}: insufficient data ({len(X_std)} samples) - SKIP')\n        continue\n    \n    X_train, X_test, y_train, y_test = train_test_split(X_std, y_std, test_size=0.2, random_state=42)\n    \n    scaler = StandardScaler()\n    X_train_s = scaler.fit_transform(X_train)\n    X_test_s = scaler.transform(X_test)\n    \n    # Train GBClassifier with optimized hyperparameters\n    # Increased n_estimators, max_depth, and learning_rate for better feature interaction\n    gbc = GradientBoostingClassifier(\n        n_estimators=250,           # Increased from 150\n        learning_rate=0.1,          # Keep at 0.1 for stability\n        max_depth=8,                # Increased from 6 for deeper trees\n        min_samples_split=10,       # Prevent overfitting\n        min_samples_leaf=5,         # Prevent overfitting\n        subsample=0.7,              # Reduce overfitting with sampling\n        max_features='sqrt',        # Use sqrt of features\n        validation_fraction=0.1,    # Early stopping with validation\n        n_iter_no_change=20,        # Early stopping patience\n        random_state=42,\n        verbose=0\n    )\n    \n    gbc.fit(X_train_s, y_train)\n    \n    y_pred = gbc.predict(X_test_s)\n    acc = accuracy_score(y_test, y_pred)\n    \n    course_models[stadium] = {'model': gbc, 'scaler': scaler, 'features': list(X_course.columns)}\n    results_summary_course.append({'stadium': int(stadium), 'samples': len(X_std), 'accuracy': acc})\n    \n    status = '✓' if acc > 0.70 else '⚠' if acc > 0.50 else '✗'\n    print(f'{status} Stadium {int(stadium):2d}: Accuracy={acc:.1%} ({len(X_std)} samples)')\n\nif results_summary_course:\n    results_course_df = pd.DataFrame(results_summary_course)\n    print(f'\\n=== Summary ===')\n    print(f'Models trained: {len(results_course_df)}/{len(stadiums)}')\n    print(f'Average Accuracy: {results_course_df[\"accuracy\"].mean():.1%}')\n    print(f'Min Accuracy: {results_course_df[\"accuracy\"].min():.1%}')\n    print(f'Max Accuracy: {results_course_df[\"accuracy\"].max():.1%}')\nelse:\n    print('ERROR: No course models trained!')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スタート展示予測モデル"
   ],
   "id": "new-start-timing-heading"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 特徴量準備"
   ],
   "id": "new-start-timing-features"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Prepare enhanced features for start timing prediction\n",
    "print('\\n=== スタート展示予測モデル準備（強化特徴量版）===\\n')\n",
    "\n",
    "if 'スタート展示' not in final_data.columns:\n",
    "    print('ERROR: スタート展示 not found!')\n",
    "    raise KeyError('スタート展示 column missing')\n",
    "\n",
    "# Start with base features\n",
    "X_start = final_data[feature_cols].copy()\n",
    "y_start = final_data['スタート展示'].copy()\n",
    "\n",
    "# Add frame number as a feature\n",
    "X_start['枠番'] = final_data['艇番']\n",
    "\n",
    "# Add player's past start timing tendency\n",
    "player_start_tendency = final_data.groupby('登録番号')['スタート展示'].agg('mean').reset_index()\n",
    "player_start_tendency.columns = ['登録番号', 'プレイヤースタート平均']\n",
    "X_start_temp = final_data[['登録番号']].copy()\n",
    "X_start_temp = X_start_temp.merge(player_start_tendency, on='登録番号', how='left')\n",
    "X_start['プレイヤースタート傾向'] = X_start_temp['プレイヤースタート平均']\n",
    "\n",
    "# Add stadium-level average start timing per frame\n",
    "stadium_frame_start = final_data.groupby(['レース場', '艇番'])['スタート展示'].mean().reset_index()\n",
    "stadium_frame_start.columns = ['レース場', '艇番', 'スタジアム枠別平均スタート']\n",
    "X_start_temp = final_data[['レース場', '艇番']].copy()\n",
    "X_start_temp = X_start_temp.merge(stadium_frame_start, on=['レース場', '艇番'], how='left')\n",
    "X_start['スタジアム枠別平均'] = X_start_temp['スタジアム枠別平均スタート']\n",
    "\n",
    "# Add age interaction features\n",
    "X_start['年齢×枠'] = final_data['年齢'].fillna(0) * final_data['艇番']\n",
    "X_start['経験年数×枠'] = final_data['経験年数'].fillna(0) * final_data['艇番']\n",
    "\n",
    "# Convert to numeric\n",
    "for col in X_start.columns:\n",
    "    X_start[col] = pd.to_numeric(X_start[col], errors='coerce')\n",
    "\n",
    "y_start = pd.to_numeric(y_start, errors='coerce')\n",
    "\n",
    "# Fill NaN\n",
    "for col in X_start.columns:\n",
    "    median_val = X_start[col].median()\n",
    "    X_start[col].fillna(median_val if pd.notna(median_val) else 0, inplace=True)\n",
    "\n",
    "# Remove rows with missing target\n",
    "valid_start = y_start.notna()\n",
    "X_start = X_start[valid_start].reset_index(drop=True)\n",
    "y_start = y_start[valid_start].reset_index(drop=True)\n",
    "\n",
    "print(f'Base features: {len(feature_cols)}')\n",
    "print(f'Added features: 5 (枠番, プレイヤースタート傾向, スタジアム枠別平均, 年齢×枠, 経験年数×枠)')\n",
    "print(f'Total features: {len(X_start.columns)}')\n",
    "print(f'Samples: {len(X_start)}')\n",
    "print(f'Target (スタート展示) stats:')\n",
    "print(f'  Mean: {y_start.mean():.3f}s')\n",
    "print(f'  Std: {y_start.std():.3f}s')\n",
    "print(f'  Min: {y_start.min():.3f}s')\n",
    "print(f'  Max: {y_start.max():.3f}s')"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "new-start-timing-prepare"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. スタート展示予測モデル - レース場別訓練"
   ],
   "id": "new-start-timing-training"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Train start timing models per stadium\n",
    "print('\\n=== スタート展示予測モデル訓練 ===\\n')\n",
    "\n",
    "start_timing_models = {}\n",
    "results_summary_start = []\n",
    "\n",
    "for stadium in stadiums:\n",
    "    stadium_mask = final_data['レース場'] == stadium\n",
    "    X_std = X_start[stadium_mask].reset_index(drop=True)\n",
    "    y_std = y_start[stadium_mask].reset_index(drop=True)\n",
    "    \n",
    "    if len(X_std) < 100:\n",
    "        print(f'Stadium {int(stadium):2d}: insufficient data ({len(X_std)} samples) - SKIP')\n",
    "        continue\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_std, y_std, test_size=0.2, random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_test_s = scaler.transform(X_test)\n",
    "    \n",
    "    # Train GBRegressor for start timing\n",
    "    gbr_start = GradientBoostingRegressor(\n",
    "        n_estimators=150,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        random_state=42\n",
    "    )\n",
    "    gbr_start.fit(X_train_s, y_train)\n",
    "    \n",
    "    y_pred = gbr_start.predict(X_test_s)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    start_timing_models[stadium] = {'model': gbr_start, 'scaler': scaler, 'features': list(X_start.columns)}\n",
    "    results_summary_start.append({'stadium': int(stadium), 'samples': len(X_std), 'mae': mae, 'rmse': rmse})\n",
    "    \n",
    "    status = '✓' if mae < 0.10 else '⚠' if mae < 0.15 else '✗'\n",
    "    print(f'{status} Stadium {int(stadium):2d}: MAE={mae:.4f}s, RMSE={rmse:.4f}s ({len(X_std)} samples)')\n",
    "\n",
    "if results_summary_start:\n",
    "    results_start_df = pd.DataFrame(results_summary_start)\n",
    "    print(f'\\n=== Summary ===')\n",
    "    print(f'Models trained: {len(results_start_df)}/{len(stadiums)}')\n",
    "    print(f'Average MAE: {results_start_df[\"mae\"].mean():.4f}s')\n",
    "    print(f'Average RMSE: {results_start_df[\"rmse\"].mean():.4f}s')\n",
    "else:\n",
    "    print('ERROR: No start timing models trained!')"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "new-start-timing-train"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## チルト調整予測モデル"
   ],
   "id": "new-tilt-heading"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 特徴量準備"
   ],
   "id": "new-tilt-features"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Prepare enhanced features for tilt adjustment prediction\n",
    "print('\\n=== チルト調整予測モデル準備（分類タスク）===\\n')\n",
    "\n",
    "if 'チルト調整' not in final_data.columns:\n",
    "    print('ERROR: チルト調整 not found!')\n",
    "    raise KeyError('チルト調整 column missing')\n",
    "\n",
    "# Start with base features\n",
    "X_tilt = final_data[feature_cols].copy()\n",
    "y_tilt = final_data['チルト調整'].copy()\n",
    "\n",
    "# Add frame number\n",
    "X_tilt['枠番'] = final_data['艇番']\n",
    "\n",
    "# Add player's past tilt adjustment tendency\n",
    "player_tilt_tendency = final_data.groupby('登録番号')['チルト調整'].agg('mean').reset_index()\n",
    "player_tilt_tendency.columns = ['登録番号', 'プレイヤーチルト平均']\n",
    "X_tilt_temp = final_data[['登録番号']].copy()\n",
    "X_tilt_temp = X_tilt_temp.merge(player_tilt_tendency, on='登録番号', how='left')\n",
    "X_tilt['プレイヤーチルト傾向'] = X_tilt_temp['プレイヤーチルト平均']\n",
    "\n",
    "# Add stadium-level average tilt adjustment per frame\n",
    "stadium_frame_tilt = final_data.groupby(['レース場', '艇番'])['チルト調整'].mean().reset_index()\n",
    "stadium_frame_tilt.columns = ['レース場', '艇番', 'スタジアム枠別平均チルト']\n",
    "X_tilt_temp = final_data[['レース場', '艇番']].copy()\n",
    "X_tilt_temp = X_tilt_temp.merge(stadium_frame_tilt, on=['レース場', '艇番'], how='left')\n",
    "X_tilt['スタジアム枠別平均'] = X_tilt_temp['スタジアム枠別平均チルト']\n",
    "\n",
    "# Add performance interaction\n",
    "X_tilt['全国勝率×枠'] = final_data['全国勝率'].fillna(0) * final_data['艇番']\n",
    "X_tilt['当地勝率×枠'] = final_data['当地勝率'].fillna(0) * final_data['艇番']\n",
    "\n",
    "# Convert to numeric\n",
    "for col in X_tilt.columns:\n",
    "    X_tilt[col] = pd.to_numeric(X_tilt[col], errors='coerce')\n",
    "\n",
    "y_tilt = pd.to_numeric(y_tilt, errors='coerce')\n",
    "\n",
    "# Round target to nearest 0.5 for classification\n",
    "# Create categorical labels: -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, etc.\n",
    "y_tilt_rounded = (y_tilt * 2).round() / 2  # Round to nearest 0.5\n",
    "\n",
    "# Fill NaN\n",
    "for col in X_tilt.columns:\n",
    "    median_val = X_tilt[col].median()\n",
    "    X_tilt[col].fillna(median_val if pd.notna(median_val) else 0, inplace=True)\n",
    "\n",
    "# Remove rows with missing target\n",
    "valid_tilt = y_tilt_rounded.notna()\n",
    "X_tilt = X_tilt[valid_tilt].reset_index(drop=True)\n",
    "y_tilt_rounded = y_tilt_rounded[valid_tilt].reset_index(drop=True)\n",
    "\n",
    "print(f'Base features: {len(feature_cols)}')\n",
    "print(f'Added features: 5 (枠番, プレイヤーチルト傾向, スタジアム枠別平均, 全国勝率×枠, 当地勝率×枠)')\n",
    "print(f'Total features: {len(X_tilt.columns)}')\n",
    "print(f'Samples: {len(X_tilt)}')\n",
    "print(f'Target (チルト調整) classes (rounded to 0.5):')\n",
    "for val in sorted(y_tilt_rounded.unique()):\n",
    "    count = (y_tilt_rounded == val).sum()\n",
    "    pct = count / len(y_tilt_rounded) * 100\n",
    "    print(f'  {val:+.1f}: {count} ({pct:.1f}%)')"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "new-tilt-prepare"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. チルト調整予測モデル - レース場別訓練"
   ],
   "id": "new-tilt-training"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Train tilt adjustment models per stadium\n",
    "print('\\n=== チルト調整予測モデル訓練 ===\\n')\n",
    "\n",
    "tilt_adjustment_models = {}\n",
    "results_summary_tilt = []\n",
    "\n",
    "for stadium in stadiums:\n",
    "    stadium_mask = final_data['レース場'] == stadium\n",
    "    X_std = X_tilt[stadium_mask].reset_index(drop=True)\n",
    "    y_std = y_tilt_rounded[stadium_mask].reset_index(drop=True)\n",
    "    \n",
    "    if len(X_std) < 100:\n",
    "        print(f'Stadium {int(stadium):2d}: insufficient data ({len(X_std)} samples) - SKIP')\n",
    "        continue\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_std, y_std, test_size=0.2, random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_test_s = scaler.transform(X_test)\n",
    "    \n",
    "    # Train GBClassifier for tilt adjustment\n",
    "    gbc_tilt = GradientBoostingClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.08,\n",
    "        max_depth=7,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        subsample=0.75,\n",
    "        random_state=42\n",
    "    )\n",
    "    gbc_tilt.fit(X_train_s, y_train)\n",
    "    \n",
    "    y_pred = gbc_tilt.predict(X_test_s)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    tilt_adjustment_models[stadium] = {'model': gbc_tilt, 'scaler': scaler, 'features': list(X_tilt.columns)}\n",
    "    results_summary_tilt.append({'stadium': int(stadium), 'samples': len(X_std), 'accuracy': acc})\n",
    "    \n",
    "    status = '✓' if acc > 0.60 else '⚠' if acc > 0.45 else '✗'\n",
    "    print(f'{status} Stadium {int(stadium):2d}: Accuracy={acc:.1%} ({len(X_std)} samples)')\n",
    "\n",
    "if results_summary_tilt:\n",
    "    results_tilt_df = pd.DataFrame(results_summary_tilt)\n",
    "    print(f'\\n=== Summary ===')\n",
    "    print(f'Models trained: {len(results_tilt_df)}/{len(stadiums)}')\n",
    "    print(f'Average Accuracy: {results_tilt_df[\"accuracy\"].mean():.1%}')\n",
    "    print(f'Min Accuracy: {results_tilt_df[\"accuracy\"].min():.1%}')\n",
    "    print(f'Max Accuracy: {results_tilt_df[\"accuracy\"].max():.1%}')\n",
    "else:\n",
    "    print('ERROR: No tilt adjustment models trained!')"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "new-tilt-train"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved models to /Users/mahiguch/dev/boatrace/data/models/preview_models.pkl\n",
      "  Exhibition time models: 24\n",
      "  Course entry models: 24\n"
     ]
    }
   ],
   "source": [
    "# Save models\n",
    "models_data = {\n",
    "    'exhibition_time': exhibition_models,\n",
    "    'course_entry': course_models,\n",
    "    'start_timing': start_timing_models,\n",
    "    'tilt_adjustment': tilt_adjustment_models\n",
    "}\n",
    "\n",
    "model_save_path = repo_root / 'models' / 'preview_models.pkl'\n",
    "model_save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(model_save_path, 'wb') as f:\n",
    "    pickle.dump(models_data, f)\n",
    "\n",
    "print(f'✓ Saved models to {model_save_path}')\n",
    "print(f'  Exhibition time models: {len(exhibition_models)}')\n",
    "print(f'  Course entry models: {len(course_models)}')\n",
    "print(f'  Start timing models: {len(start_timing_models)}')\n",
    "print(f'  Tilt adjustment models: {len(tilt_adjustment_models)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2026年1月のテストデータで予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. テストデータ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 31 days of test data for 2026-01\n"
     ]
    }
   ],
   "source": [
    "# Load test data for 2026-01\n",
    "test_data_list = []\n",
    "\n",
    "year_test = '2026'\n",
    "month_test = '01'\n",
    "month_num = int(month_test)\n",
    "year_num = int(year_test)\n",
    "\n",
    "_, max_day = calendar.monthrange(year_num, month_num)\n",
    "\n",
    "for day in range(1, max_day + 1):\n",
    "    day_str = f'{day:02d}'\n",
    "    prog_path = repo_root / 'data' / 'programs' / year_test / month_test / f'{day_str}.csv'\n",
    "    \n",
    "    if prog_path.exists():\n",
    "        try:\n",
    "            prog_test = pd.read_csv(prog_path)\n",
    "            test_data_list.append((day_str, prog_test))\n",
    "        except Exception as e:\n",
    "            print(f'Error loading {year_test}-{month_test}-{day_str}: {e}')\n",
    "\n",
    "print(f'✓ Loaded {len(test_data_list)} days of test data for 2026-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. テストデータの変形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Test programs reshaped: (31350, 37)\n"
     ]
    }
   ],
   "source": [
    "# Reshape test programs and add environment info from previews\n",
    "test_programs_list = []\n",
    "\n",
    "for day, prog_test in test_data_list:\n",
    "    prog_reshaped = reshape_programs(prog_test)\n",
    "    \n",
    "    if not prog_reshaped.empty:\n",
    "        # Map stadium\n",
    "        prog_reshaped['レース場'] = prog_reshaped['レース場'].apply(map_stadium_name_to_number)\n",
    "        prog_reshaped = prog_reshaped[prog_reshaped['レース場'].notna()].reset_index(drop=True)\n",
    "        \n",
    "        # Load previews for this day to get environment info\n",
    "        prev_path = repo_root / 'data' / 'previews' / '2026' / '01' / f'{day}.csv'\n",
    "        if prev_path.exists():\n",
    "            try:\n",
    "                prev_test = pd.read_csv(prev_path)\n",
    "                prev_reshaped = reshape_previews(prev_test)\n",
    "                \n",
    "                # Extract environment columns from previews\n",
    "                environment_cols = ['レースコード', '風速(m)', '波の高さ(cm)', '気温(℃)', '水温(℃)']\n",
    "                available_env = [c for c in environment_cols if c in prev_reshaped.columns]\n",
    "                \n",
    "                if available_env:\n",
    "                    prev_env = prev_reshaped[available_env].drop_duplicates()\n",
    "                    prog_reshaped = prog_reshaped.merge(prev_env, on='レースコード', how='left')\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        \n",
    "        # Add date column\n",
    "        prog_reshaped['日付'] = day\n",
    "        \n",
    "        if not prog_reshaped.empty:\n",
    "            test_programs_list.append(prog_reshaped)\n",
    "\n",
    "if test_programs_list:\n",
    "    test_programs = pd.concat(test_programs_list, ignore_index=True)\n",
    "    print(f'✓ Test programs reshaped: {test_programs.shape}')\n",
    "else:\n",
    "    print('✗ No test programs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 特徴量準備と予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained models and prepare test features with enhanced features\n",
    "with open(model_save_path, 'rb') as f:\n",
    "    models_data = pickle.load(f)\n",
    "\n",
    "exhibition_models = models_data['exhibition_time']\n",
    "course_models = models_data['course_entry']\n",
    "start_timing_models = models_data['start_timing']\n",
    "tilt_adjustment_models = models_data['tilt_adjustment']\n",
    "\n",
    "print(f'✓ Loaded exhibition time models: {len(exhibition_models)}')\n",
    "print(f'✓ Loaded course entry models: {len(course_models)}')\n",
    "print(f'✓ Loaded start timing models: {len(start_timing_models)}')\n",
    "print(f'✓ Loaded tilt adjustment models: {len(tilt_adjustment_models)}')\n",
    "\n",
    "# Get expected feature lists from trained models\n",
    "expected_course_features = course_models[list(course_models.keys())[0]]['features']\n",
    "expected_start_features = start_timing_models[list(start_timing_models.keys())[0]]['features']\n",
    "expected_tilt_features = tilt_adjustment_models[list(tilt_adjustment_models.keys())[0]]['features']\n",
    "\n",
    "print(f'Expected course features: {len(expected_course_features)}')\n",
    "print(f'Expected start timing features: {len(expected_start_features)}')\n",
    "print(f'Expected tilt adjustment features: {len(expected_tilt_features)}')\n",
    "\n",
    "# Prepare test features for start timing prediction\n",
    "X_test_start = test_programs[feature_cols].copy()\n",
    "X_test_start['枠番'] = test_programs['艇番']\n",
    "\n",
    "# Add player's start timing tendency\n",
    "player_start_tendency = final_data.groupby('登録番号')['スタート展示'].agg('mean').reset_index()\n",
    "player_start_tendency.columns = ['登録番号', 'プレイヤースタート平均']\n",
    "X_start_temp = test_programs[['登録番号']].copy()\n",
    "X_start_temp = X_start_temp.merge(player_start_tendency, on='登録番号', how='left')\n",
    "X_test_start['プレイヤースタート傾向'] = X_start_temp['プレイヤースタート平均']\n",
    "\n",
    "# Add stadium-frame average start timing\n",
    "stadium_frame_start = final_data.groupby(['レース場', '艇番'])['スタート展示'].mean().reset_index()\n",
    "stadium_frame_start.columns = ['レース場', '艇番', 'スタジアム枠別平均スタート']\n",
    "X_start_temp = test_programs[['レース場', '艇番']].copy()\n",
    "X_start_temp = X_start_temp.merge(stadium_frame_start, on=['レース場', '艇番'], how='left')\n",
    "X_test_start['スタジアム枠別平均'] = X_start_temp['スタジアム枠別平均スタート']\n",
    "\n",
    "# Add age interactions\n",
    "X_test_start['年齢×枠'] = test_programs['年齢'].fillna(0) * test_programs['艇番']\n",
    "X_test_start['経験年数×枠'] = test_programs['経験年数'].fillna(0) * test_programs['艇番']\n",
    "\n",
    "# Convert to numeric and fill NaN\n",
    "for col in X_test_start.columns:\n",
    "    X_test_start[col] = pd.to_numeric(X_test_start[col], errors='coerce')\n",
    "\n",
    "for col in X_test_start.columns:\n",
    "    if col in X_start.columns:\n",
    "        median_val = X_start[col].median()\n",
    "    else:\n",
    "        median_val = np.nan\n",
    "    \n",
    "    if pd.isna(median_val):\n",
    "        X_test_start[col].fillna(0, inplace=True)\n",
    "    else:\n",
    "        X_test_start[col].fillna(median_val, inplace=True)\n",
    "\n",
    "# Prepare test features for tilt adjustment prediction\n",
    "X_test_tilt = test_programs[feature_cols].copy()\n",
    "X_test_tilt['枠番'] = test_programs['艇番']\n",
    "\n",
    "# Add player's tilt tendency\n",
    "player_tilt_tendency = final_data.groupby('登録番号')['チルト調整'].agg('mean').reset_index()\n",
    "player_tilt_tendency.columns = ['登録番号', 'プレイヤーチルト平均']\n",
    "X_tilt_temp = test_programs[['登録番号']].copy()\n",
    "X_tilt_temp = X_tilt_temp.merge(player_tilt_tendency, on='登録番号', how='left')\n",
    "X_test_tilt['プレイヤーチルト傾向'] = X_tilt_temp['プレイヤーチルト平均']\n",
    "\n",
    "# Add stadium-frame average tilt\n",
    "stadium_frame_tilt = final_data.groupby(['レース場', '艇番'])['チルト調整'].mean().reset_index()\n",
    "stadium_frame_tilt.columns = ['レース場', '艇番', 'スタジアム枠別平均チルト']\n",
    "X_tilt_temp = test_programs[['レース場', '艇番']].copy()\n",
    "X_tilt_temp = X_tilt_temp.merge(stadium_frame_tilt, on=['レース場', '艇番'], how='left')\n",
    "X_test_tilt['スタジアム枠別平均'] = X_tilt_temp['スタジアム枠別平均チルト']\n",
    "\n",
    "# Add performance interactions\n",
    "X_test_tilt['全国勝率×枠'] = test_programs['全国勝率'].fillna(0) * test_programs['艇番']\n",
    "X_test_tilt['当地勝率×枠'] = test_programs['当地勝率'].fillna(0) * test_programs['艇番']\n",
    "\n",
    "# Convert to numeric and fill NaN\n",
    "for col in X_test_tilt.columns:\n",
    "    X_test_tilt[col] = pd.to_numeric(X_test_tilt[col], errors='coerce')\n",
    "\n",
    "for col in X_test_tilt.columns:\n",
    "    if col in X_tilt.columns:\n",
    "        median_val = X_tilt[col].median()\n",
    "    else:\n",
    "        median_val = np.nan\n",
    "    \n",
    "    if pd.isna(median_val):\n",
    "        X_test_tilt[col].fillna(0, inplace=True)\n",
    "    else:\n",
    "        X_test_tilt[col].fillna(median_val, inplace=True)\n",
    "\n",
    "# Prepare for exhibition time and course prediction (use original features)\n",
    "X_test_exhibition = test_programs[feature_cols].copy()\n",
    "for col in X_test_exhibition.columns:\n",
    "    X_test_exhibition[col] = pd.to_numeric(X_test_exhibition[col], errors='coerce')\n",
    "\n",
    "for col in X_test_exhibition.columns:\n",
    "    if col in X.columns:\n",
    "        median_val = X[col].median()\n",
    "    else:\n",
    "        median_val = np.nan\n",
    "    \n",
    "    if pd.isna(median_val):\n",
    "        X_test_exhibition[col].fillna(0, inplace=True)\n",
    "    else:\n",
    "        X_test_exhibition[col].fillna(median_val, inplace=True)\n",
    "\n",
    "# Prepare for course prediction (uses enhanced features)\n",
    "X_test_course = test_programs[feature_cols].copy()\n",
    "X_test_course['枠番'] = test_programs['艇番']\n",
    "\n",
    "# Add player's course entry tendency\n",
    "player_course_tendency = final_data.groupby('登録番号')['コース'].agg(lambda x: x.mode()[0] if len(x.mode()) > 0 else x.median()).reset_index()\n",
    "player_course_tendency.columns = ['登録番号', 'プレイヤー進入傾向コース']\n",
    "X_course_temp = test_programs[['登録番号']].copy()\n",
    "X_course_temp = X_course_temp.merge(player_course_tendency, on='登録番号', how='left')\n",
    "X_test_course['プレイヤー進入傾向'] = X_course_temp['プレイヤー進入傾向コース']\n",
    "\n",
    "# Add stadium-frame average course\n",
    "stadium_frame_course = final_data.groupby(['レース場', '艇番'])['コース'].mean().reset_index()\n",
    "stadium_frame_course.columns = ['レース場', '艇番', 'スタジアム枠別平均コース']\n",
    "X_course_temp = test_programs[['レース場', '艇番']].copy()\n",
    "X_course_temp = X_course_temp.merge(stadium_frame_course, on=['レース場', '艇番'], how='left')\n",
    "X_test_course['スタジアム枠別平均'] = X_course_temp['スタジアム枠別平均コース']\n",
    "\n",
    "# Add player win rate interactions\n",
    "X_test_course['全国勝率×枠'] = test_programs['全国勝率'].fillna(0) * test_programs['艇番']\n",
    "X_test_course['当地勝率×枠'] = test_programs['当地勝率'].fillna(0) * test_programs['艇番']\n",
    "\n",
    "# Convert to numeric and fill NaN for course\n",
    "for col in X_test_course.columns:\n",
    "    X_test_course[col] = pd.to_numeric(X_test_course[col], errors='coerce')\n",
    "\n",
    "for col in X_test_course.columns:\n",
    "    if col in X_course.columns:\n",
    "        median_val = X_course[col].median()\n",
    "    else:\n",
    "        median_val = np.nan\n",
    "    \n",
    "    if pd.isna(median_val):\n",
    "        X_test_course[col].fillna(0, inplace=True)\n",
    "    else:\n",
    "        X_test_course[col].fillna(median_val, inplace=True)\n",
    "\n",
    "print(f'✓ Test features prepared for exhibition time: {X_test_exhibition.shape}')\n",
    "print(f'✓ Test features prepared for course entry: {X_test_course.shape}')\n",
    "print(f'✓ Test features prepared for start timing: {X_test_start.shape}')\n",
    "print(f'✓ Test features prepared for tilt adjustment: {X_test_tilt.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 展示タイム予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Exhibition time predictions: 31350 successful, 0 errors\n",
      "  Valid predictions: 31350/31350\n",
      "  Mean: 6.794s, Std: 0.050s\n"
     ]
    }
   ],
   "source": [
    "# Predict exhibition times\n",
    "exhibition_predictions = []\n",
    "success_count = 0\n",
    "error_count = 0\n",
    "\n",
    "for idx, row in test_programs.iterrows():\n",
    "    stadium = row['レース場']\n",
    "    \n",
    "    if stadium not in exhibition_models:\n",
    "        exhibition_predictions.append(np.nan)\n",
    "        continue\n",
    "    \n",
    "    model_info = exhibition_models[stadium]\n",
    "    model = model_info['model']\n",
    "    scaler = model_info['scaler']\n",
    "    \n",
    "    try:\n",
    "        X_row = X_test_exhibition.iloc[idx:idx+1]\n",
    "        X_scaled = scaler.transform(X_row)\n",
    "        pred = model.predict(X_scaled)[0]\n",
    "        \n",
    "        # Clamp to reasonable range (e.g., 5.0 to 8.0 seconds)\n",
    "        pred = max(5.0, min(8.0, pred))\n",
    "        \n",
    "        exhibition_predictions.append(pred)\n",
    "        success_count += 1\n",
    "    except Exception as e:\n",
    "        exhibition_predictions.append(np.nan)\n",
    "        error_count += 1\n",
    "\n",
    "test_programs['展示タイム'] = exhibition_predictions\n",
    "\n",
    "print(f'✓ Exhibition time predictions: {success_count} successful, {error_count} errors')\n",
    "print(f'  Valid predictions: {test_programs[\"展示タイム\"].notna().sum()}/{len(test_programs)}')\n",
    "if test_programs[\"展示タイム\"].notna().sum() > 0:\n",
    "    print(f'  Mean: {test_programs[\"展示タイム\"].mean():.3f}s, Std: {test_programs[\"展示タイム\"].std():.3f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 進入コース予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Course entry predictions: 31350 successful, 0 errors\n",
      "  Valid predictions: 31350/31350\n",
      "  Distribution: {1: 6189, 2: 5031, 3: 5088, 4: 5398, 5: 5372, 6: 4272}\n"
     ]
    }
   ],
   "source": [
    "# Predict course entries\n",
    "course_predictions = []\n",
    "success_count = 0\n",
    "error_count = 0\n",
    "\n",
    "for idx, row in test_programs.iterrows():\n",
    "    stadium = row['レース場']\n",
    "    \n",
    "    if stadium not in course_models:\n",
    "        course_predictions.append(np.nan)\n",
    "        continue\n",
    "    \n",
    "    model_info = course_models[stadium]\n",
    "    model = model_info['model']\n",
    "    scaler = model_info['scaler']\n",
    "    \n",
    "    try:\n",
    "        X_row = X_test_course.iloc[idx:idx+1]\n",
    "        X_scaled = scaler.transform(X_row)\n",
    "        pred = model.predict(X_scaled)[0]\n",
    "        \n",
    "        # Ensure it's in valid range (1-6)\n",
    "        pred = max(1, min(6, int(pred)))\n",
    "        \n",
    "        course_predictions.append(pred)\n",
    "        success_count += 1\n",
    "    except Exception as e:\n",
    "        course_predictions.append(np.nan)\n",
    "        error_count += 1\n",
    "\n",
    "test_programs['コース'] = course_predictions\n",
    "\n",
    "print(f'✓ Course entry predictions: {success_count} successful, {error_count} errors')\n",
    "print(f'  Valid predictions: {test_programs[\"コース\"].notna().sum()}/{len(test_programs)}')\n",
    "if test_programs[\"コース\"].notna().sum() > 0:\n",
    "    print(f'  Distribution: {test_programs[\"コース\"].value_counts().sort_index().to_dict()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. スタート展示予測"
   ],
   "id": "pred-start-timing"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Predict start timings\n",
    "start_timing_predictions = []\n",
    "success_count = 0\n",
    "error_count = 0\n",
    "\n",
    "for idx, row in test_programs.iterrows():\n",
    "    stadium = row['レース場']\n",
    "    \n",
    "    if stadium not in start_timing_models:\n",
    "        start_timing_predictions.append(np.nan)\n",
    "        continue\n",
    "    \n",
    "    model_info = start_timing_models[stadium]\n",
    "    model = model_info['model']\n",
    "    scaler = model_info['scaler']\n",
    "    \n",
    "    try:\n",
    "        X_row = X_test_start.iloc[idx:idx+1]\n",
    "        X_scaled = scaler.transform(X_row)\n",
    "        pred = model.predict(X_scaled)[0]\n",
    "        \n",
    "        # Clamp to reasonable range (e.g., -0.5 to 1.0 seconds)\n",
    "        pred = max(-0.5, min(1.0, pred))\n",
    "        \n",
    "        start_timing_predictions.append(pred)\n",
    "        success_count += 1\n",
    "    except Exception as e:\n",
    "        start_timing_predictions.append(np.nan)\n",
    "        error_count += 1\n",
    "\n",
    "test_programs['スタート展示'] = start_timing_predictions\n",
    "\n",
    "print(f'✓ Start timing predictions: {success_count} successful, {error_count} errors')\n",
    "print(f'  Valid predictions: {test_programs[\"スタート展示\"].notna().sum()}/{len(test_programs)}')\n",
    "if test_programs[\"スタート展示\"].notna().sum() > 0:\n",
    "    print(f'  Mean: {test_programs[\"スタート展示\"].mean():.3f}s, Std: {test_programs[\"スタート展示\"].std():.3f}s')"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "pred-start-timing-code"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. チルト調整予測"
   ],
   "id": "pred-tilt"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Predict tilt adjustments\n",
    "tilt_adjustment_predictions = []\n",
    "success_count = 0\n",
    "error_count = 0\n",
    "\n",
    "for idx, row in test_programs.iterrows():\n",
    "    stadium = row['レース場']\n",
    "    \n",
    "    if stadium not in tilt_adjustment_models:\n",
    "        tilt_adjustment_predictions.append(np.nan)\n",
    "        continue\n",
    "    \n",
    "    model_info = tilt_adjustment_models[stadium]\n",
    "    model = model_info['model']\n",
    "    scaler = model_info['scaler']\n",
    "    \n",
    "    try:\n",
    "        X_row = X_test_tilt.iloc[idx:idx+1]\n",
    "        X_scaled = scaler.transform(X_row)\n",
    "        pred = model.predict(X_scaled)[0]\n",
    "        \n",
    "        # Pred is already rounded to nearest 0.5 during training\n",
    "        # Clamp to reasonable range (e.g., -1.0 to 2.5)\n",
    "        pred = max(-1.0, min(2.5, float(pred)))\n",
    "        \n",
    "        tilt_adjustment_predictions.append(pred)\n",
    "        success_count += 1\n",
    "    except Exception as e:\n",
    "        tilt_adjustment_predictions.append(np.nan)\n",
    "        error_count += 1\n",
    "\n",
    "test_programs['チルト調整'] = tilt_adjustment_predictions\n",
    "\n",
    "print(f'✓ Tilt adjustment predictions: {success_count} successful, {error_count} errors')\n",
    "print(f'  Valid predictions: {test_programs[\"チルト調整\"].notna().sum()}/{len(test_programs)}')\n",
    "if test_programs[\"チルト調整\"].notna().sum() > 0:\n",
    "    print(f'  Distribution:')\n",
    "    dist = test_programs[\"チルト調整\"][test_programs[\"チルト調整\"].notna()].round(1).value_counts().sort_index()\n",
    "    for val, count in dist.items():\n",
    "        print(f'    {val:+.1f}: {count}')"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "pred-tilt-code"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測Previews形式での出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Prepared output: (5128, 16)\n",
      "  Sample:\n",
      "         レースコード        レース日  レース場 レース回  艇1_コース  艇1_展示タイム  艇2_コース  艇2_展示タイム  \\\n",
      "0  202601012301  2026-01-01    23   1R       6  6.864569       3  6.810665   \n",
      "1  202601012302  2026-01-01    23   2R       4  6.855010       3  6.870603   \n",
      "2  202601012303  2026-01-01    23   3R       2  6.884915       2  6.904967   \n",
      "\n",
      "   艇3_コース  艇3_展示タイム  艇4_コース  艇4_展示タイム  艇5_コース  艇5_展示タイム  艇6_コース  艇6_展示タイム  \n",
      "0       6  6.811533       5  6.934221       5  6.890248       5  6.859225  \n",
      "1       6  6.887283       6  6.853288       5  6.874995       2  6.861927  \n",
      "2       1  6.791930       5  6.854584       2  6.859013       1  6.857827  \n"
     ]
    }
   ],
   "source": [
    "# Prepare predicted previews output\n",
    "# Output format: one row per race, with columns for each boat\n",
    "\n",
    "output_data = {}\n",
    "\n",
    "for race_code in test_programs['レースコード'].unique():\n",
    "    race_programs = test_programs[test_programs['レースコード'] == race_code]\n",
    "    \n",
    "    if len(race_programs) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Get race-level info from first boat\n",
    "    first_row = race_programs.iloc[0]\n",
    "    race_info = {\n",
    "        'レースコード': race_code,\n",
    "        'レース日': first_row['レース日'],\n",
    "        'レース場': int(first_row['レース場']),\n",
    "        'レース回': first_row['レース回']\n",
    "    }\n",
    "    \n",
    "    # Add boat-specific predictions for all 4 models\n",
    "    for _, row in race_programs.iterrows():\n",
    "        boat_num = int(row['艇番'])\n",
    "        race_info[f'艇{boat_num}_展示タイム'] = row['展示タイム']\n",
    "        race_info[f'艇{boat_num}_コース'] = row['コース']\n",
    "        race_info[f'艇{boat_num}_スタート展示'] = row['スタート展示']\n",
    "        race_info[f'艇{boat_num}_チルト調整'] = row['チルト調整']\n",
    "    \n",
    "    output_data[race_code] = race_info\n",
    "\n",
    "# Convert to DataFrame\n",
    "output_df = pd.DataFrame(list(output_data.values()))\n",
    "\n",
    "# Sort columns: race info first, then by boat and prediction type\n",
    "cols_first = ['レースコード', 'レース日', 'レース場', 'レース回']\n",
    "cols_other = sorted([c for c in output_df.columns if c not in cols_first])\n",
    "output_df = output_df[cols_first + cols_other]\n",
    "\n",
    "print(f'✓ Prepared output: {output_df.shape}')\n",
    "print(f'  Sample:')\n",
    "print(output_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV出力（日別）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/01.csv (154 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/02.csv (189 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/03.csv (213 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/04.csv (228 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/05.csv (180 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/06.csv (180 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/07.csv (180 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/08.csv (165 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/09.csv (144 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/10.csv (144 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/11.csv (180 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/12.csv (169 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/13.csv (167 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/14.csv (166 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/15.csv (155 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/16.csv (142 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/17.csv (179 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/18.csv (190 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/19.csv (176 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/20.csv (156 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/21.csv (156 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/22.csv (156 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/23.csv (156 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/24.csv (156 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/25.csv (156 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/26.csv (191 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/27.csv (168 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/28.csv (133 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/29.csv (130 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/30.csv (129 races)\n",
      "✓ Saved /Users/mahiguch/dev/boatrace/data/data/prediction-preview/2026/01/31.csv (140 races)\n",
      "\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "# Save predictions by date\n",
    "output_dir = repo_root / 'data' / 'prediction-preview' / '2026' / '01'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Group by date\n",
    "for date_str in test_programs['レース日'].unique():\n",
    "    if pd.isna(date_str):\n",
    "        continue\n",
    "    \n",
    "    date_programs = test_programs[test_programs['レース日'] == date_str]\n",
    "    \n",
    "    # Create date key from race code\n",
    "    race_codes = date_programs['レースコード'].unique()\n",
    "    if len(race_codes) > 0:\n",
    "        first_race_code = str(race_codes[0])\n",
    "        if len(first_race_code) >= 8:\n",
    "            year = first_race_code[:4]\n",
    "            month = first_race_code[4:6]\n",
    "            day = first_race_code[6:8]\n",
    "            \n",
    "            # Filter output for this date\n",
    "            date_output = output_df[output_df['レース日'] == date_str]\n",
    "            \n",
    "            # Save\n",
    "            output_path = output_dir / f'{day}.csv'\n",
    "            date_output.to_csv(output_path, index=False)\n",
    "            print(f'✓ Saved {output_path} ({len(date_output)} races)')\n",
    "\n",
    "print('\\nAll done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}