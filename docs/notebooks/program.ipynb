{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Programs のみを用いた着順予想モデル\n",
    "\n",
    "対象：2016年～2025年のデータを使用して、ボートレース場ごとに着順予想モデルを構築。\n",
    "- データソース: programs のみ（風向、天候は使用しない）\n",
    "- 学習対象: 日次が3日目以降のレースのみ\n",
    "- モデル: GradientBoostingClassifier（レース場ごと）\n",
    "- 予想・的中率検証: 2026年1月1日～30日"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import calendar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Setup complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## データ変形関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshape functions ready\n",
      "Stadium extraction from race code ready\n",
      "Stadium name to number mapping ready\n"
     ]
    }
   ],
   "source": [
    "def reshape_programs(df):\n",
    "    \"\"\"\n",
    "    Programs を艇単位に変形\n",
    "    各艇について、レース情報と艇固有情報（選手、モーター、ボート）を1行に\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    race_cols = ['レースコード', '日次', 'レース日', 'レース場', 'レース回']\n",
    "    \n",
    "    for frame in range(1, 7):\n",
    "        prefix = f'{frame}枠_'\n",
    "        cols = [c for c in df.columns if c.startswith(prefix)]\n",
    "        if cols:\n",
    "            tmp = df[race_cols + cols].copy()\n",
    "            tmp.columns = race_cols + [c[len(prefix):] for c in cols]\n",
    "            tmp['枠'] = frame\n",
    "            frames.append(tmp)\n",
    "    \n",
    "    return pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
    "\n",
    "def reshape_results(df):\n",
    "    \"\"\"\n",
    "    Results を艇単位に変形\n",
    "    着順情報を艇番とマッチングして1行に集約\n",
    "    新形式: 〇着_艇番 というカラム形式に対応\n",
    "    \"\"\"\n",
    "    result_list = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        race_code = row['レースコード']\n",
    "        \n",
    "        # Try to find boat numbers for each position\n",
    "        for place in range(1, 7):\n",
    "            boat_col = f'{place}着_艇番'\n",
    "            \n",
    "            # Check if column exists\n",
    "            if boat_col not in df.columns:\n",
    "                continue\n",
    "                \n",
    "            boat_num = row[boat_col]\n",
    "            \n",
    "            # Skip if boat number is NaN or invalid\n",
    "            if pd.isna(boat_num):\n",
    "                continue\n",
    "            \n",
    "            # Handle both int and float types\n",
    "            try:\n",
    "                boat_num = int(boat_num)\n",
    "                if boat_num < 1 or boat_num > 6:\n",
    "                    continue\n",
    "                    \n",
    "                result_list.append({\n",
    "                    'レースコード': race_code,\n",
    "                    '艇番': boat_num,\n",
    "                    '着順': place\n",
    "                })\n",
    "            except (ValueError, TypeError):\n",
    "                continue\n",
    "    \n",
    "    return pd.DataFrame(result_list) if result_list else pd.DataFrame()\n",
    "\n",
    "def extract_day_number(day_str):\n",
    "    \"\"\"\n",
    "    日次文字列から数値を抽出\n",
    "    '第1日' -> 1, '第2日' -> 2, etc.\n",
    "    \"\"\"\n",
    "    if pd.isna(day_str):\n",
    "        return np.nan\n",
    "    day_str = str(day_str)\n",
    "    if '第' in day_str and '日' in day_str:\n",
    "        try:\n",
    "            return int(day_str.replace('第', '').replace('日', ''))\n",
    "        except:\n",
    "            return np.nan\n",
    "    return np.nan\n",
    "\n",
    "print('Reshape functions ready')\n",
    "# Stadium name to number mapping\n",
    "\n",
    "# Stadium code from レースコード to standard stadium number (1-24)\n",
    "RACE_CODE_TO_STADIUM = {\n",
    "    0: 17,   # 唐津\n",
    "    6: 6,    # 浜名湖\n",
    "    7: 7,    # 蒲郡\n",
    "    8: 8,    # 常滑\n",
    "    9: 9,    # 津\n",
    "    10: 10,  # 三国\n",
    "    16: 13,  # 丸亀\n",
    "    19: 21,  # 徳山\n",
    "    20: 20,  # 下関\n",
    "    22: 19,  # 芦屋\n",
    "    24: 18,  # 大村\n",
    "}\n",
    "\n",
    "def extract_stadium_from_race_code(race_code):\n",
    "    \"\"\"\n",
    "    レースコードから競艇場番号を抽出\n",
    "    レースコード形式: YYYYMMDDCCRRwhere CC is stadium code (positions 8-10)\n",
    "    \"\"\"\n",
    "    if pd.isna(race_code):\n",
    "        return np.nan\n",
    "    race_code_str = str(race_code)\n",
    "    if len(race_code_str) >= 10:\n",
    "        try:\n",
    "            stadium_code = int(race_code_str[8:10])\n",
    "            return RACE_CODE_TO_STADIUM.get(stadium_code, np.nan)\n",
    "        except:\n",
    "            return np.nan\n",
    "    return np.nan\n",
    "\n",
    "print('Stadium extraction from race code ready')\n",
    "\n",
    "# Stadium name to standard number mapping (1-24)\n",
    "# Note: びわこ can be written as 琵琶湖 in some data versions\n",
    "STADIUM_NAME_TO_NUMBER = {\n",
    "    'ボートレース桐生': 1,\n",
    "    'ボートレース戸田': 2,\n",
    "    'ボートレース江戸川': 3,\n",
    "    'ボートレース平和島': 4,\n",
    "    'ボートレース多摩川': 5,\n",
    "    'ボートレース浜名湖': 6,\n",
    "    'ボートレース蒲郡': 7,\n",
    "    'ボートレース常滑': 8,\n",
    "    'ボートレース津': 9,\n",
    "    'ボートレース三国': 10,\n",
    "    'ボートレースびわこ': 11,\n",
    "    'ボートレース琵琶湖': 11,  # Alternative name for びわこ\n",
    "    'ボートレース住之江': 12,\n",
    "    'ボートレース尼崎': 13,\n",
    "    'ボートレース鳴門': 14,\n",
    "    'ボートレース丸亀': 15,\n",
    "    'ボートレース児島': 16,\n",
    "    'ボートレース宮島': 17,\n",
    "    'ボートレース徳山': 18,\n",
    "    'ボートレース下関': 19,\n",
    "    'ボートレース若松': 20,\n",
    "    'ボートレース芦屋': 21,\n",
    "    'ボートレース福岡': 22,\n",
    "    'ボートレース唐津': 23,\n",
    "    'ボートレース大村': 24,\n",
    "}\n",
    "\n",
    "def map_stadium_name_to_number(stadium_name):\n",
    "    \"\"\"\n",
    "    競艇場の名前から標準番号（1-24）に変換\n",
    "    \"\"\"\n",
    "    if pd.isna(stadium_name):\n",
    "        return np.nan\n",
    "    stadium_name = str(stadium_name).strip()\n",
    "    return STADIUM_NAME_TO_NUMBER.get(stadium_name, np.nan)\n",
    "\n",
    "print('Stadium name to number mapping ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2016～2025年のデータで学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "### 1. データ読み込み（2016～2025年）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/mahiguch/dev/boatrace/data/docs/notebooks\n",
      "Repository root: /Users/mahiguch/dev/boatrace/data\n",
      "Loaded 3649 days (2016-2025)\n"
     ]
    }
   ],
   "source": [
    "cwd = Path.cwd()\n",
    "repo_root = cwd if (cwd / 'data').exists() else cwd.parent.parent\n",
    "\n",
    "print(f'Current working directory: {cwd}')\n",
    "print(f'Repository root: {repo_root}')\n",
    "\n",
    "# Load data for 2016-2025\n",
    "all_data = {}\n",
    "years = [str(y) for y in range(2016, 2026)]\n",
    "\n",
    "for year in years:\n",
    "    for month in range(1, 13):\n",
    "        # Get the number of days in this month\n",
    "        _, max_day = calendar.monthrange(int(year), month)\n",
    "        for day in range(1, max_day + 1):\n",
    "            month_str = f'{month:02d}'\n",
    "            day_str = f'{day:02d}'\n",
    "            prog_path = repo_root / 'data' / 'programs' / year / month_str / f'{day_str}.csv'\n",
    "            res_path = repo_root / 'data' / 'results' / year / month_str / f'{day_str}.csv'\n",
    "            \n",
    "            if prog_path.exists() and res_path.exists():\n",
    "                date_key = f'{year}-{month_str}-{day_str}'\n",
    "                try:\n",
    "                    all_data[date_key] = {\n",
    "                        'programs': pd.read_csv(prog_path),\n",
    "                        'results': pd.read_csv(res_path)\n",
    "                    }\n",
    "                except Exception as e:\n",
    "                    print(f'Error loading {date_key}: {e}')\n",
    "\n",
    "print(f'Loaded {len(all_data)} days (2016-2025)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7b",
   "metadata": {},
   "source": [
    "### 2. データ統合（stadium 1-24のみ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3649 days...\n",
      "✓ Processed 3649 days successfully\n",
      "\n",
      "✓ Final: (3309152, 36)\n",
      "✓ Unique dates: 3649\n",
      "✓ Stadiums: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "✓ Stadium count: 24\n",
      "✓ Target missing: 807114 rows\n"
     ]
    }
   ],
   "source": [
    "combined_data = []\n",
    "errors = []\n",
    "\n",
    "print(f'Processing {len(all_data)} days...')\n",
    "processed_count = 0\n",
    "skipped_count = 0\n",
    "\n",
    "for date_str, data in all_data.items():\n",
    "    try:\n",
    "        prog = reshape_programs(data['programs'])\n",
    "        res = reshape_results(data['results'])\n",
    "        \n",
    "        if prog.empty or res.empty:\n",
    "            continue\n",
    "        \n",
    "        # Extract day number\n",
    "        prog['日次数'] = prog['日次'].apply(extract_day_number)\n",
    "        \n",
    "        # Map stadium name to number\n",
    "        prog['レース場'] = prog['レース場'].apply(map_stadium_name_to_number)\n",
    "        \n",
    "        # Remove rows with unknown stadium\n",
    "        prog = prog[prog['レース場'].notna()].reset_index(drop=True)\n",
    "        \n",
    "        if prog.empty:\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        # Merge with results using レースコード\n",
    "        merged = prog.merge(\n",
    "            res[['レースコード', '艇番', '着順']],\n",
    "            on=['レースコード', '艇番'],\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        combined_data.append(merged)\n",
    "        processed_count += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        errors.append((date_str, type(e).__name__))\n",
    "\n",
    "print(f'✓ Processed {processed_count} days successfully')\n",
    "if skipped_count > 0:\n",
    "    print(f'⚠ Skipped {skipped_count} days (no mapped stadiums)')\n",
    "if errors:\n",
    "    print(f'✗ Errors: {len(errors)}')\n",
    "\n",
    "if combined_data:\n",
    "    final_data = pd.concat(combined_data, ignore_index=True)\n",
    "    print(f'\\n✓ Final: {final_data.shape}')\n",
    "    print(f'✓ Unique dates: {final_data[\"レース日\"].nunique()}')\n",
    "    stadiums = sorted(final_data[\"レース場\"].dropna().unique())\n",
    "    print(f'✓ Stadiums: {[int(s) for s in stadiums]}')\n",
    "    print(f'✓ Stadium count: {len(stadiums)}')\n",
    "    print(f'✓ Target missing: {final_data[\"着順\"].isna().sum()} rows')\n",
    "else:\n",
    "    print('\\n✗ ERROR: No data merged!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "### 3. 特徴量準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ final_data loaded successfully\n",
      "Total NaN count after filling: 0\n",
      "\n",
      "Features: 23\n",
      "Samples: 3309152\n",
      "Stadiums: 24\n",
      "Target missing: 807114\n"
     ]
    }
   ],
   "source": [
    "# Check if final_data exists\n",
    "if 'final_data' not in locals():\n",
    "    print('\\n' + '='*70)\n",
    "    print('ERROR: final_data not defined')\n",
    "    print('='*70)\n",
    "    print('\\nPossible causes:')\n",
    "    print('1. Cell-7 failed to load data (all_data is empty)')\n",
    "    print('2. Cell-8 failed to merge data (combined_data is empty)')\n",
    "    print('3. Stadium filter excluded all rows')\n",
    "    print('\\nAction: Run cell-7 and cell-8 again and check their output above.')\n",
    "    print('='*70)\n",
    "    raise NameError('final_data not defined - check cells 7 and 8')\n",
    "\n",
    "print('✓ final_data loaded successfully')\n",
    "\n",
    "if 'final_data' not in locals():\n",
    "    print('ERROR: final_data not defined. Check cell-7 and cell-8.')\n",
    "    print('This usually means data loading or merging failed.')\n",
    "    raise NameError('final_data not defined')\n",
    "\n",
    "exclude_cols = {\n",
    "    'レースコード', '日次', 'レース日', 'レース場', 'レース回',\n",
    "    '艇番', '登録番号', '選手名', '支部',\n",
    "    '枠', '着順', '日次数',\n",
    "    'モーター番号', 'ボート番号'  # IDs, not features\n",
    "}\n",
    "\n",
    "categorical_cols = {'級別'}\n",
    "\n",
    "numeric_cols = []\n",
    "for col in final_data.columns:\n",
    "    if col not in exclude_cols and col not in categorical_cols:\n",
    "        try:\n",
    "            pd.to_numeric(final_data[col], errors='coerce')\n",
    "            numeric_cols.append(col)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "X = final_data[numeric_cols].copy()\n",
    "\n",
    "for col in X.columns:\n",
    "    X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "for col in X.columns:\n",
    "    median_val = X[col].median()\n",
    "    if pd.isna(median_val):\n",
    "        X[col].fillna(0, inplace=True)\n",
    "    else:\n",
    "        X[col].fillna(median_val, inplace=True)\n",
    "\n",
    "if '級別' in final_data.columns:\n",
    "    le_grade = LabelEncoder()\n",
    "    X['級別_encoded'] = le_grade.fit_transform(final_data['級別'].fillna('未知'))\n",
    "\n",
    "X['日次数'] = final_data['日次数'].fillna(1).astype(int)\n",
    "\n",
    "total_nan = X.isna().sum().sum()\n",
    "print(f'Total NaN count after filling: {total_nan}')\n",
    "\n",
    "y = final_data['着順']\n",
    "stadiums = sorted(final_data['レース場'].unique())\n",
    "\n",
    "print(f'\\nFeatures: {len(X.columns)}')\n",
    "print(f'Samples: {len(X)}')\n",
    "print(f'Stadiums: {len(stadiums)}')\n",
    "print(f'Target missing: {y.isna().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "### 4. モデル学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== モデル学習結果 ===\n",
      " stadium  accuracy  samples\n",
      "       1  0.245026   135549\n",
      "       2  0.239704   136862\n",
      "       3  0.228728   124337\n",
      "       4  0.240525   127345\n",
      "       5  0.237856   120633\n",
      "       6  0.245498   141780\n",
      "       7  0.244620   137082\n",
      "       8  0.247745   141529\n",
      "       9  0.242493   123547\n",
      "      10  0.254109   133840\n",
      "      11  0.251832    66869\n",
      "      12  0.237324   135299\n",
      "      13  0.179033    64288\n",
      "      14  0.178766    69290\n",
      "      15  0.182146    74903\n",
      "      16  0.189448    70379\n",
      "      17  0.187979    70821\n",
      "      18  0.188289    67341\n",
      "      19  0.193120    61239\n",
      "      20  0.186136    70734\n",
      "      21  0.193711    67316\n",
      "      22  0.184274    56383\n",
      "      23  0.248160   128626\n",
      "      24  0.238895   176046\n",
      "\n",
      "成功: 24 / 24 スタジアム\n"
     ]
    }
   ],
   "source": [
    "results_summary = []\n",
    "\n",
    "for stadium in stadiums:\n",
    "    mask = final_data['レース場'] == stadium\n",
    "    X_std = X[mask].reset_index(drop=True)\n",
    "    y_std = y[mask].reset_index(drop=True)\n",
    "    \n",
    "    # Remove missing targets\n",
    "    valid = y_std.notna()\n",
    "    X_std = X_std[valid].reset_index(drop=True)\n",
    "    y_std = y_std[valid].reset_index(drop=True)\n",
    "    \n",
    "    if len(X_std) < 10:\n",
    "        print(f'Stadium {int(stadium)}: insufficient data ({len(X_std)} samples)')\n",
    "        continue\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_std, y_std, test_size=0.3, random_state=42\n",
    "    )\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_test_s = scaler.transform(X_test)\n",
    "    \n",
    "    # GBC\n",
    "    try:\n",
    "        gbc = GradientBoostingClassifier(\n",
    "            n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42\n",
    "        )\n",
    "        gbc.fit(X_train_s, y_train)\n",
    "        acc = accuracy_score(y_test, gbc.predict(X_test_s))\n",
    "        results_summary.append({'stadium': int(stadium), 'accuracy': acc, 'samples': len(X_std)})\n",
    "    except Exception as e:\n",
    "        print(f'Stadium {int(stadium)} error: {type(e).__name__}: {str(e)[:50]}')\n",
    "\n",
    "if results_summary:\n",
    "    results_df = pd.DataFrame(results_summary)\n",
    "    print('\\n=== モデル学習結果 ===')\n",
    "    print(results_df.to_string(index=False))\n",
    "    print(f'\\n成功: {len(results_df)} / {len(stadiums)} スタジアム')\n",
    "else:\n",
    "    print('学習失敗')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "### 5. モデル保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 保存: 24 モデルを /Users/mahiguch/dev/boatrace/data/models/program_models.pkl に保存\n"
     ]
    }
   ],
   "source": [
    "# Store models and scaler info\n",
    "models_dict = {}\n",
    "\n",
    "for stadium in stadiums:\n",
    "    mask = final_data['レース場'] == stadium\n",
    "    X_std = X[mask].reset_index(drop=True)\n",
    "    y_std = y[mask].reset_index(drop=True)\n",
    "    \n",
    "    # Remove missing targets\n",
    "    valid = y_std.notna()\n",
    "    X_std = X_std[valid].reset_index(drop=True)\n",
    "    y_std = y_std[valid].reset_index(drop=True)\n",
    "    \n",
    "    if len(X_std) < 10:\n",
    "        continue\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_std, y_std, test_size=0.3, random_state=42\n",
    "    )\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # Train GBC model\n",
    "    gbc = GradientBoostingClassifier(\n",
    "        n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42\n",
    "    )\n",
    "    gbc.fit(X_train_s, y_train)\n",
    "    \n",
    "    models_dict[stadium] = {\n",
    "        'model': gbc,\n",
    "        'scaler': scaler,\n",
    "        'features': list(X.columns)\n",
    "    }\n",
    "\n",
    "# Save models\n",
    "model_save_path = repo_root / 'models' / 'program_models.pkl'\n",
    "model_save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(model_save_path, 'wb') as f:\n",
    "    pickle.dump(models_dict, f)\n",
    "\n",
    "print(f'✓ 保存: {len(models_dict)} モデルを {model_save_path} に保存')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 2026年1月1日～30日のデータで予想"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "### 1. テストデータ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 30 days for 2026-01\n"
     ]
    }
   ],
   "source": [
    "# Load data for 2026-01\n",
    "test_data_list = []\n",
    "\n",
    "year_test = '2026'\n",
    "month_test = '01'\n",
    "month_num = int(month_test)\n",
    "year_num = int(year_test)\n",
    "\n",
    "_, max_day = calendar.monthrange(year_num, month_num)\n",
    "\n",
    "for day in range(1, max_day + 1):\n",
    "    day_str = f'{day:02d}'\n",
    "    prog_path = repo_root / 'data' / 'programs' / year_test / month_test / f'{day_str}.csv'\n",
    "    res_path = repo_root / 'data' / 'results' / year_test / month_test / f'{day_str}.csv'\n",
    "    \n",
    "    if prog_path.exists() and res_path.exists():\n",
    "        try:\n",
    "            prog_test = pd.read_csv(prog_path)\n",
    "            res_test = pd.read_csv(res_path)\n",
    "            test_data_list.append((day_str, prog_test, res_test))\n",
    "        except Exception as e:\n",
    "            print(f'Error loading {year_test}-{month_test}-{day_str}: {e}')\n",
    "\n",
    "print(f'✓ Loaded {len(test_data_list)} days for 2026-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17b",
   "metadata": {},
   "source": [
    "### 2. テストデータの変形とマージ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Test data merged: (30441, 36)\n",
      "✓ Unique stadiums: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "✓ Actual results available: 21441 rows\n"
     ]
    }
   ],
   "source": [
    "# Reshape and merge test data\n",
    "test_combined = []\n",
    "\n",
    "for day, prog_test, res_test in test_data_list:\n",
    "    prog_reshaped = reshape_programs(prog_test)\n",
    "    res_reshaped = reshape_results(res_test)\n",
    "    \n",
    "    if prog_reshaped.empty or res_reshaped.empty:\n",
    "        continue\n",
    "    \n",
    "    # Extract day number\n",
    "    prog_reshaped['日次数'] = prog_reshaped['日次'].apply(extract_day_number)\n",
    "    \n",
    "    # Map stadium name to number\n",
    "    prog_reshaped['レース場'] = prog_reshaped['レース場'].apply(map_stadium_name_to_number)\n",
    "    \n",
    "    # Remove rows with unknown stadium\n",
    "    prog_reshaped = prog_reshaped[prog_reshaped['レース場'].notna()].reset_index(drop=True)\n",
    "    \n",
    "    if prog_reshaped.empty:\n",
    "        continue\n",
    "    \n",
    "    # Merge\n",
    "    test_data = prog_reshaped.merge(\n",
    "        res_reshaped[['レースコード', '艇番', '着順']],\n",
    "        on=['レースコード', '艇番'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    test_combined.append(test_data)\n",
    "\n",
    "if test_combined:\n",
    "    test_data = pd.concat(test_combined, ignore_index=True)\n",
    "    print(f'✓ Test data merged: {test_data.shape}')\n",
    "    stadiums = sorted(test_data[\"レース場\"].dropna().unique())\n",
    "    print(f'✓ Unique stadiums: {[int(s) for s in stadiums]}')\n",
    "    print(f'✓ Actual results available: {test_data[\"着順\"].notna().sum()} rows')\n",
    "else:\n",
    "    print('✗ No test data available')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "### 3. 予想実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24 models\n",
      "Stadiums with models: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14), np.int64(15), np.int64(16), np.int64(17), np.int64(18), np.int64(19), np.int64(20), np.int64(21), np.int64(22), np.int64(23), np.int64(24)]\n",
      "Expected features from saved model: ['年齢', '体重', '全国勝率', '全国2連対率', '当地勝率', '当地2連対率', 'モーター2連対率', 'ボート2連対率', '今節成績_1-1', '今節成績_1-2', '今節成績_2-1', '今節成績_2-2', '今節成績_3-1', '今節成績_3-2', '今節成績_4-1', '今節成績_4-2', '今節成績_5-1', '今節成績_5-2', '今節成績_6-1', '今節成績_6-2', '早見', '級別_encoded', '日次数']\n",
      "Number of features: 23\n",
      "\n",
      "Stadiums in test data: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14), np.int64(15), np.int64(16), np.int64(17), np.int64(18), np.int64(19), np.int64(20), np.int64(21), np.int64(22), np.int64(23), np.int64(24)]\n",
      "Stadiums NOT in models: set()\n",
      "\n",
      "First 10 rows details:\n",
      "  Row 0: レースコード=202601012301, レース場=23, 日次=第6日, 日次数=6\n",
      "  Row 1: レースコード=202601012302, レース場=23, 日次=第6日, 日次数=6\n",
      "  Row 2: レースコード=202601012303, レース場=23, 日次=第6日, 日次数=6\n",
      "  Row 3: レースコード=202601012304, レース場=23, 日次=第6日, 日次数=6\n",
      "  Row 4: レースコード=202601012305, レース場=23, 日次=第6日, 日次数=6\n",
      "  Row 5: レースコード=202601012306, レース場=23, 日次=第6日, 日次数=6\n",
      "  Row 6: レースコード=202601012307, レース場=23, 日次=第6日, 日次数=6\n",
      "  Row 7: レースコード=202601012308, レース場=23, 日次=第6日, 日次数=6\n",
      "  Row 8: レースコード=202601012309, レース場=23, 日次=第6日, 日次数=6\n",
      "  Row 9: レースコード=202601012310, レース場=23, 日次=第6日, 日次数=6\n",
      "\n",
      "X_test_pred shape: (30441, 23)\n",
      "X_test_pred columns match expected: True\n",
      "\n",
      "\n",
      "=== 予想結果 ===\n",
      "成功: 30441\n",
      "モデルなし: 0\n",
      "エラー: 0\n",
      "\n",
      "サンプル予想:\n",
      "          レースコード  艇番  レース場  日次数      予想三連単\n",
      "0   202601012301   1    23    6  (1, 2, 3)\n",
      "1   202601012302   1    23    6  (2, 1, 4)\n",
      "2   202601012303   1    23    6  (1, 2, 4)\n",
      "3   202601012304   1    23    6  (5, 6, 4)\n",
      "4   202601012305   1    23    6  (2, 3, 1)\n",
      "5   202601012306   1    23    6  (1, 2, 3)\n",
      "6   202601012307   1    23    6  (5, 4, 6)\n",
      "7   202601012308   1    23    6  (5, 4, 6)\n",
      "8   202601012309   1    23    6  (5, 2, 4)\n",
      "9   202601012310   1    23    6  (1, 2, 3)\n",
      "10  202601012311   1    23    6  (1, 2, 3)\n",
      "11  202601012312   1    23    6  (1, 2, 3)\n",
      "12  202601012201   1    21    4  (1, 3, 4)\n",
      "13  202601012203   1    21    4  (1, 2, 3)\n",
      "14  202601012205   1    21    4  (4, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load saved models\n",
    "with open(model_save_path, 'rb') as f:\n",
    "    models_dict = pickle.load(f)\n",
    "\n",
    "print(f'Loaded {len(models_dict)} models')\n",
    "print(f'Stadiums with models: {sorted(models_dict.keys())}')\n",
    "\n",
    "# Get expected features from the first model\n",
    "first_stadium = list(models_dict.keys())[0]\n",
    "expected_features = models_dict[first_stadium]['features']\n",
    "print(f'Expected features from saved model: {expected_features}')\n",
    "print(f'Number of features: {len(expected_features)}')\n",
    "\n",
    "# Check test data stadiums\n",
    "test_stadiums = test_data['レース場'].unique()\n",
    "print(f'\\nStadiums in test data: {sorted(test_stadiums)}')\n",
    "print(f'Stadiums NOT in models: {set(test_stadiums) - set(models_dict.keys())}')\n",
    "\n",
    "# Check first few rows\n",
    "print(f'\\nFirst 10 rows details:')\n",
    "for idx in range(min(10, len(test_data))):\n",
    "    row = test_data.iloc[idx]\n",
    "    print(f'  Row {idx}: レースコード={row[\"レースコード\"]}, レース場={row[\"レース場\"]}, 日次={row[\"日次\"]}, 日次数={row[\"日次数\"]}')\n",
    "\n",
    "# Prepare features for prediction using the SAME features as training\n",
    "# Build features in the same order as training\n",
    "X_test_pred = pd.DataFrame(index=test_data.index)\n",
    "\n",
    "# Add numeric features\n",
    "for col in numeric_cols:\n",
    "    if col in test_data.columns:\n",
    "        X_test_pred[col] = pd.to_numeric(test_data[col], errors='coerce')\n",
    "    else:\n",
    "        print(f'Warning: {col} not in test_data, filling with 0')\n",
    "        X_test_pred[col] = 0.0\n",
    "\n",
    "# Fill NaN with median from training data\n",
    "for col in numeric_cols:\n",
    "    median_val = X[col].median()\n",
    "    X_test_pred[col].fillna(median_val, inplace=True)\n",
    "\n",
    "# Add encoded categorical\n",
    "if '級別_encoded' in expected_features:\n",
    "    if '級別' in test_data.columns:\n",
    "        X_test_pred['級別_encoded'] = le_grade.transform(test_data['級別'].fillna('未知'))\n",
    "    else:\n",
    "        X_test_pred['級別_encoded'] = 0\n",
    "\n",
    "# Add day number\n",
    "if '日次数' in expected_features:\n",
    "    X_test_pred['日次数'] = test_data['日次数'].fillna(1).astype(int)\n",
    "\n",
    "# Ensure columns are in the EXACT same order as expected\n",
    "X_test_pred = X_test_pred[expected_features]\n",
    "\n",
    "print(f'\\nX_test_pred shape: {X_test_pred.shape}')\n",
    "print(f'X_test_pred columns match expected: {list(X_test_pred.columns) == expected_features}')\n",
    "\n",
    "# Function to generate prediction\n",
    "def predict_sanrentan(model, scaler, X_row):\n",
    "    X_scaled = scaler.transform(X_row)\n",
    "    proba = model.predict_proba(X_scaled)[0]\n",
    "    classes = model.classes_\n",
    "    \n",
    "    prob_dict = {cls: prob for cls, prob in zip(classes, proba)}\n",
    "    sorted_probs = sorted(prob_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    top_3 = sorted_probs[:3]\n",
    "    return top_3\n",
    "\n",
    "# Make predictions for Sanrentan\n",
    "sanrentan_predictions = []\n",
    "errors_log = []\n",
    "success_count = 0\n",
    "no_model_count = 0\n",
    "\n",
    "for idx, row in test_data.iterrows():\n",
    "    stadium = row['レース場']\n",
    "    \n",
    "    # Skip if no model for this stadium\n",
    "    if stadium not in models_dict:\n",
    "        sanrentan_predictions.append(None)\n",
    "        no_model_count += 1\n",
    "        if no_model_count <= 5:  # Log first 5 missing stadiums\n",
    "            errors_log.append(f'Row {idx}: No model for stadium {stadium}')\n",
    "        continue\n",
    "    \n",
    "    model_info = models_dict[stadium]\n",
    "    model = model_info['model']\n",
    "    scaler = model_info['scaler']\n",
    "    \n",
    "    # Prepare features\n",
    "    X_row = X_test_pred.iloc[idx:idx+1]\n",
    "    \n",
    "    try:\n",
    "        top_3 = predict_sanrentan(model, scaler, X_row)\n",
    "        top_boats = [int(boat) for boat, _ in top_3]\n",
    "        sanrentan_predictions.append(tuple(top_boats))\n",
    "        success_count += 1\n",
    "    except Exception as e:\n",
    "        if len(errors_log) < 10:  # Log first 10 errors\n",
    "            errors_log.append(f'Row {idx} (stadium {stadium}): {type(e).__name__}: {str(e)[:80]}')\n",
    "        sanrentan_predictions.append(None)\n",
    "\n",
    "test_data['予想三連単'] = sanrentan_predictions\n",
    "\n",
    "print(f'\\n\\n=== 予想結果 ===')\n",
    "print(f'成功: {success_count}')\n",
    "print(f'モデルなし: {no_model_count}')\n",
    "print(f'エラー: {test_data[\"予想三連単\"].isna().sum() - no_model_count}')\n",
    "if errors_log:\n",
    "    print(f'\\nログ:')\n",
    "    for err in errors_log:\n",
    "        print(f'  {err}')\n",
    "print(f'\\nサンプル予想:')\n",
    "print(test_data[['レースコード', '艇番', 'レース場', '日次数', '予想三連単']].head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "### 4. 的中率の計算（三連単）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Race-level Sanrentan results: 3554 races\n",
      "Race-level predictions: 4988 races\n",
      "\n",
      "三連単的中率: 108/3554 = 3.04%\n"
     ]
    }
   ],
   "source": [
    "# レースコード単位で三連単の着順を取得\n",
    "race_actual_sanrentan = {}\n",
    "for race_code in test_data['レースコード'].unique():\n",
    "    race_mask = test_data['レースコード'] == race_code\n",
    "    race_subset = test_data[race_mask].sort_values('着順')\n",
    "    \n",
    "    # 1着～3着の艇番を取得\n",
    "    sanrentan = tuple(race_subset[race_subset['着順'].notna()].head(3)['艇番'].astype(int).values)\n",
    "    if len(sanrentan) == 3:\n",
    "        race_actual_sanrentan[race_code] = sanrentan\n",
    "\n",
    "print(f'Race-level Sanrentan results: {len(race_actual_sanrentan)} races')\n",
    "\n",
    "# レース単位での予想を集計\n",
    "race_predictions = {}\n",
    "for race_code in test_data['レースコード'].unique():\n",
    "    race_mask = test_data['レースコード'] == race_code\n",
    "    race_subset = test_data[race_mask]\n",
    "    \n",
    "    # 最初の行から予想三連単を取得\n",
    "    if race_subset['予想三連単'].notna().any():\n",
    "        race_predictions[race_code] = race_subset['予想三連単'].iloc[0]\n",
    "\n",
    "print(f'Race-level predictions: {len(race_predictions)} races')\n",
    "\n",
    "# 的中判定\n",
    "sanrentan_matches = []\n",
    "for race_code in race_actual_sanrentan.keys():\n",
    "    if race_code in race_predictions:\n",
    "        actual = race_actual_sanrentan[race_code]\n",
    "        predicted = race_predictions[race_code]\n",
    "        \n",
    "        is_match = (predicted == actual)\n",
    "        sanrentan_matches.append({\n",
    "            'レースコード': race_code,\n",
    "            '予想三連単': predicted,\n",
    "            '実績三連単': actual,\n",
    "            '的中': is_match\n",
    "        })\n",
    "\n",
    "if sanrentan_matches:\n",
    "    sanrentan_df = pd.DataFrame(sanrentan_matches)\n",
    "    correct = sanrentan_df['的中'].sum()\n",
    "    total = len(sanrentan_df)\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    \n",
    "    print(f'\\n三連単的中率: {correct}/{total} = {accuracy:.2%}')\n",
    "else:\n",
    "    print('的中判定可能なデータなし')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "### 5. 詳細結果（1着、2着、3着別の的中率）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 的中率レポート（Programs のみモデル）===\n",
      "レース数: 3554\n",
      "1着的中: 1133/3554 (31.9%)\n",
      "2着的中: 694/3554 (19.5%)\n",
      "3着的中: 653/3554 (18.4%)\n",
      "三連単的中: 108/3554 (3.0%)\n"
     ]
    }
   ],
   "source": [
    "# Create detailed comparison results\n",
    "results_list = []\n",
    "\n",
    "for race_code in sorted(race_actual_sanrentan.keys()):\n",
    "    if race_code in race_predictions:\n",
    "        predicted = race_predictions[race_code]\n",
    "        actual = race_actual_sanrentan[race_code]\n",
    "        \n",
    "        # Extract each position\n",
    "        pred_1st, pred_2nd, pred_3rd = predicted[0], predicted[1], predicted[2]\n",
    "        actual_1st, actual_2nd, actual_3rd = actual[0], actual[1], actual[2]\n",
    "        \n",
    "        # Check matches\n",
    "        match_1st = '○' if pred_1st == actual_1st else '×'\n",
    "        match_2nd = '○' if pred_2nd == actual_2nd else '×'\n",
    "        match_3rd = '○' if pred_3rd == actual_3rd else '×'\n",
    "        match_all = '○' if (pred_1st == actual_1st and pred_2nd == actual_2nd and pred_3rd == actual_3rd) else '×'\n",
    "        \n",
    "        results_list.append({\n",
    "            'レースコード': race_code,\n",
    "            '予想1着': pred_1st,\n",
    "            '予想2着': pred_2nd,\n",
    "            '予想3着': pred_3rd,\n",
    "            '実際1着': actual_1st,\n",
    "            '実際2着': actual_2nd,\n",
    "            '実際3着': actual_3rd,\n",
    "            '1着的中': match_1st,\n",
    "            '2着的中': match_2nd,\n",
    "            '3着的中': match_3rd,\n",
    "            '全的中': match_all\n",
    "        })\n",
    "\n",
    "if results_list:\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_races = len(results_df)\n",
    "    match_1st_count = (results_df['1着的中'] == '○').sum()\n",
    "    match_2nd_count = (results_df['2着的中'] == '○').sum()\n",
    "    match_3rd_count = (results_df['3着的中'] == '○').sum()\n",
    "    match_all_count = (results_df['全的中'] == '○').sum()\n",
    "    \n",
    "    print('=== 的中率レポート（Programs のみモデル）===')\n",
    "    print(f'レース数: {total_races}')\n",
    "    print(f'1着的中: {match_1st_count}/{total_races} ({match_1st_count/total_races:.1%})')\n",
    "    print(f'2着的中: {match_2nd_count}/{total_races} ({match_2nd_count/total_races:.1%})')\n",
    "    print(f'3着的中: {match_3rd_count}/{total_races} ({match_3rd_count/total_races:.1%})')\n",
    "    print(f'三連単的中: {match_all_count}/{total_races} ({match_all_count/total_races:.1%})')\n",
    "else:\n",
    "    print('No results to display')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "### 6. 推定結果を CSV に出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to: /Users/mahiguch/dev/boatrace/data/data/estimate/2026/01/program_estimate.csv\n",
      "Total predictions: 4988\n"
     ]
    }
   ],
   "source": [
    "# レース単位で三連単の予想を整形して出力\n",
    "output_records = []\n",
    "\n",
    "for race_code in sorted(race_predictions.keys()):\n",
    "    predicted_sanrentan = race_predictions[race_code]\n",
    "    if predicted_sanrentan is not None:\n",
    "        output_records.append({\n",
    "            'レースコード': race_code,\n",
    "            '予想1着': predicted_sanrentan[0],\n",
    "            '予想2着': predicted_sanrentan[1],\n",
    "            '予想3着': predicted_sanrentan[2]\n",
    "        })\n",
    "\n",
    "if output_records:\n",
    "    output_df = pd.DataFrame(output_records)\n",
    "    \n",
    "    # 出力ディレクトリを作成\n",
    "    output_dir = repo_root / 'data' / 'estimate' / '2026' / '01'\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # ファイル名\n",
    "    output_path = output_dir / 'program_estimate.csv'\n",
    "    \n",
    "    # CSV に出力\n",
    "    output_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f'Output saved to: {output_path}')\n",
    "    print(f'Total predictions: {len(output_df)}')\n",
    "else:\n",
    "    print('No predictions to output')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
